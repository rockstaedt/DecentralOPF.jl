\chead{\textit{Application}}  				
\section{Application}

As already mentioned in the previous chapter, the majority of the analyzed papers utilizing \gls{admm} to solve economic dispatch problems or optimal power flows in a decentralized manner do so without a thorough description of neither the mathematical formulations nor the implementation of the latter. In order to tackle this issue, the following chapter describes in detail the derivation of the decentralized optimal power flow problem. First, the reader is introduced to the modeling framework. Then, the transformation of the centralized problem to the decentralized problem formulation is explained. Lastly, the implementation of the optimization problem in Julia is covered.

\subsection{Modeling Framework}
\label{sec:app:mod-framework}

This section introduces the reader to all relevant information about the modeling framework that is used to model a real-life application. The modeling framework has to cover certain requirements. Firstly, there should be generators that produce electrical power. The power output is only limited by the maximum capacity of the generator. There exist no ramping constraints or minimum up- and down-times. Each generator has marginal costs and is connected to a specific node. To depict these requirements in Julia, a generator structure was implemented as you can see in the following code snippet. In addition to the stated requirements, the structure also contains a color and a name. These attributes are mainly used for evaluation reasons and are not important for modeling purposes. 

\lstinputlisting[language=julia, firstline=7, lastline=13, caption=Structure for a node element]{../src/structures/network_elements.jl}

Another part of the modeling framework is a storage unit. Storages should be able to store a surplus of energy as well as deliver electrical power by discharging their capacity. The power input and output is also limited. In addition, a storage unit should only be able to store a certain amount of energy. This is depicted by the storage level. As generators, storages have specific marginal costs for charging and discharging and are connected to a specific node. A Julia structure was implemented respectively. As written before, generators and storages are located at network nodes. These nodes have a specific demand that should be matched by the output of the generating units. For modeling purposes, it is also crucial to define a slack node to compensate the power flow balance. The node structure was implemented as follows:

\lstinputlisting[language=julia, firstline=1, lastline=5, caption=Structure for a generator element]{../src/structures/network_elements.jl}

The last element of the framework is a transmission line. This element connects nodes and enables the exchange of energy. Transmission lines are characterized by their maximum capacity and their susceptance value. A Julia structure was also implemented for this network element.Lastly, the modeling framework has to consider multi-periods. This is crucial since without multi periods, it would not make sense to include storages into the system. All structures are defined in \path{src\structures\network_elements.jl} and can be found in \ref{sec:appendix:jl:structures:ne}.


\subsection{Mathematical Formulations}
\label{sec:app:math-form}

As written in the introduction, the aim of this thesis is to develop a framework to minimize the total system costs of a electrical network in a decentralized manner. This means that the costs are optimized without a central entity. Thus, the generating units are able to derive their own optimal decisions without releasing sensible information like their marginal costs. This section presents the mathematical formulations of the optimization problem. Since the solution of the decentralized problem will be compared with the solution of the centralized problem and the decentralized problem is based on the centralized problem, the centralized optimization model is introduced first.

\subsubsection{Centralized Optimization Problem}

The total system costs of an electrical network are the sum of generation costs of all participating units over all time steps. With regard to the modeling framework, this means that the system costs are composed of the generator costs and the storage costs. The centralized optimization problem can be formulated as follows:

\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}} \quad \sum_{g\in\mathcal{G}}mc_g \cdot P_{g,t} + \sum_{s\in\mathcal{S}}mc_s \cdot (D_{s,t}+C_{s,t})\\[10pt]
		 \text{s.t. } \quad & 0 \leq P_{g,t} \leq \overline{p_g} && \forall g \in \set{G}, t \in \set{T} \label{eq:com:con:max-g}\\
		 & 0 \leq D_{s,t} \leq \overline{p_s} && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:max-sd}\\
		 & 0 \leq C_{s,t} \leq \overline{p_s} && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:max-sc}\\
		 & 0 \leq E_{s,t} \leq \overline{e_s} && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:s-level-max}\\
		 & E_{s,t} - E_{s,t-1} - C_{s,t} + D_{s,t} = 0 && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:s-level}\\
		 & \sum_{n \in \mathcal{N}} I_{n,t} = 0 && \forall t \in \set{T} \label{eq:com:con:eb}\\
		 & -\overline{f_l} \leq PTDF_{l,n} \cdot I_{n,t} \leq \overline{f_l} && \forall l \in \set{L}, t \in \set{T}, n \in \set{N} \label{eq:com:con:pf}
	\end{align}
\end{subequations}

Hereby, $\mathcal{G}$ represents the set of generators and $\mathcal{S}$ the set of storage respectively. $\mathcal{T}$ includes all considered time steps. The optimization problem is constrained to meet the requirements described in section (\ref{sec:app:mod-framework}). First of all, equation (\ref{eq:com:con:max-g}) limits the maximum output of all generators where $\overline{p_g}$ is the maximum power generation of the considered generator. Equations (\ref{eq:com:con:max-sd}) and (\ref{eq:com:con:max-sc}) set the power boundaries of all storages respectively. Equation (\ref{eq:com:con:s-level-max}) ensures that the storage level of all storages remains between zero and the maximum storage level $\overline{e_s}$. In addition, this constraint prevents the storage from discharging power more than the energy is stored. The energy level of a storage $s$ at a specific timestep $t$ can be calculated as follows:

\begin{equation}
	\label{eq:storage-level}
	E_{s,t} = E_{s,t-1} + C_{s,t} - D_{s,t}
\end{equation}

To get a consistent form of all constraints, equation (\ref{eq:storage-level}) is rearranged to equal zero and integrated in the optimization problem as equation (\ref{eq:com:con:s-level}). $C_{s,t}$ denotes the charging output of a storage $s$ at a time step $t$ and $D_{s,t}$ the discharging power output. Another requirement of the previous section was that the demand at every node and every time step $d_{n,t}$ is met by the generating units. This is the so called energy balance. Due to the fact that the system allows line flows on the transmission lines, it can happen that the production at a node exceeds the nodal demand. Thus, to make sure that all nodal demands are met, the sum of all nodal injections has to be zero, see equation (\ref{eq:com:con:eb}). The injection at a node $n$ and at at time step $t$ yields:

\begin{equation}
	I_{n,t} = \sum_{g\in\mathcal{G}_n}P_{g,t} + \sum_{s\in\mathcal{S}_n}(D_{s,t}-C_{s,t})-d_{n,t}
	\label{eq:injection-term}
\end{equation}

Here, $\mathcal{G}_n$ ($\mathcal{S}_n$) represents a subset of all generators (storages) that are located at node $n$. Hence, the injection is basically the sum of the power values of all generators and storages at that node. This injection term is also used in the last constraint (\ref{eq:com:con:pf}) that establishes the network constraints. Here, the line flows on each transmission line are limited by the maximum line capacity $\overline{f_l}$. The line flow of a transmission line $l$ is calculated by multiplying the power distribution factors of that line with the injection term $I_{n,t}$ of a specific node $n$.\\

	%TODO Explain PTDF, see maybe document from EMOD.
	
To solve the optimization problem, all relevant information has to be shared with the central entity. In the example above this includes marginal costs and the maximal capacities of the generating units. The central entity is then able to derive the optimal dispatch plan that minimizes the total system costs and informs the generating units about their generation schedule. Thus, the generating units are not able to optimize their decision on their own because the central entity is needed for coordination.	

\subsubsection{Decentralized Optimization Problem}
\label{sec:app:dom}

% TODO Add reference for ADMM explanation
The generating units in the centralized optimization problem are not able to optimize on their own because a central entity is needed to coordinate the system constraints (\ref{eq:com:con:eb}) and (\ref{eq:com:con:pf}). These constraints prevent that the solution is obtained by optimizing per generating unit because both include all decision variables of the optimization problem. This is the reason why these constraints are called complicating constraints. If resolved, it would be possible to derive the optimal dispatch plan per generating unit and without sharing sensible information like marginal costs. As written in \ref{admm}, the \gls{admm} provides a technique to resolve these constraints, making the problem decomposable and thus enables the path to a decentralized mechanism. \gls{admm} is only working for equality constraints. Thus, the power flow inequality constraint (\ref{eq:com:con:pf}) is transformed into two equality constraints by introducing two slack variables $U_{l,t}$ and $K_{l,t}$ for each transmission line $l$ and time step $t$. The optimization problem evolves to the following:

\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}} \quad \sum_{g\in\mathcal{G}}mc_g \cdot P_{g,t} + \sum_{s\in\mathcal{S}}mc_s \cdot (D_{s,t}+C_{s,t}) \label{eq:dom:relaxed-constraints}\\[10pt]
		 \text{s.t. } \quad & 0 \leq P_{g,t} \leq \overline{p_g} && \forall g \in \set{G}, t \in \set{T}\\
		 & 0 \leq D_{s,t} \leq \overline{p_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq C_{s,t} \leq \overline{p_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq E_{s,t} \leq \overline{e_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & E_{s,t} - E_{s,t-1} - C_{s,t} + D_{s,t} = 0 && \forall s \in \set{S}, t \in \set{T}\\
		 & \sum_{n \in \mathcal{N}} I_{n,t} = 0 && \forall t \in \set{T} \\
		 & \sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} + U_{l,t} - \overline{f_l} = 0 && \forall l \in \mathcal{L}, t \in \set{T} \label{eq:dom:con:pf-upper} \\
		 & \sum_{n \in \mathcal{N}} K_{l,t} - PTDF_{l,n} \cdot I_{n,t} - \overline{f_l} = 0 && \forall l \in \mathcal{L}, t \in \set{T} \label{eq:dom:con:pf-lower}
	\end{align}
\end{subequations}

The slack variable $U_{l,t}$ ensures that the upper bound of the transmission line capacity is kept, while slack variable $K_{l,t}$ ensures the lower limit. Both variables are added as additional decision variables. Instead of two complicating constraints, one has to handle three complicating constraints. If these constraints are relaxed, the main problem decomposes into a generator and a storage subproblem.\\

Relaxing the complicating variables is done by implementing a max-min problem using the dual variables of the complicated constraints. Hereby, $\lambda$ is the dual of the energy balance constraint, $\mu$ and $\rho$ are the duals of the upper and lower power flow constraint respectively. Since the objective function is a linear cost function, \gls{lr} is not applicable. Thus, the complicated constraints are relaxed by applying \gls{alr}. A penalty term for each dual variable is introduced. The penalty terms equal zero in the optimality point and contribute to a faster convergence. The optimization problem of (\ref{eq:dom:relaxed-constraints}) derives to:

\begin{subequations}
	\begin{align}
		\max{(\lambda, \mu, \rho)} \label{eq:dom:fixed-duals} \\
		\min \quad \sum_{t\in\mathcal{T}} \quad & \sum_{g\in\mathcal{G}}mc_g \cdot P_{g,t} + \sum_{s\in\mathcal{S}}mc_s \cdot (D_{s,t}+C_{s,t}) \nonumber \\
		 & + \lambda_t \cdot \sum_{n \in \mathcal{N}} I_{n,t} \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\|\sum_{n \in \mathcal{N}} I_{n,t}\big\|^2_2 \nonumber \\
		 & +  \sum_{l \in \mathcal{L}} \quad \mu_{l,t} \cdot (\sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} + U_{l,t} - \overline{f_l}) \nonumber \\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\| \sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} + U_{l,t} - \overline{f_l} \big\|^2_2 \nonumber \\
		 & \qquad \qquad + \rho_{l,t} \cdot (\sum_{n \in \mathcal{N}} K_{l,t} - PTDF_{l,n} \cdot I_{n,t} - \overline{f_l}) \nonumber \\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\|\sum_{n \in \mathcal{N}} K_{l,t} - PTDF_{l,n} \cdot I_{n,t} - \overline{f_l} \big\|^2_2 \nonumber
	\end{align}
	\begin{align}
		 \text{s.t. } \quad & 0 \leq P_{g,t} \leq \overline{p_g} && \forall g \in \set{G}, t \in \set{T}\\
		 & 0 \leq D_{s,t} \leq \overline{p_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq C_{s,t} \leq \overline{p_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq E_{s,t} \leq \overline{e_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & E_{s,t} - E_{s,t-1} - C_{s,t} + D_{s,t} = 0 && \forall s \in \set{S}, t \in \set{T}
	\end{align}
\end{subequations}

Variable $\gamma$ is a positive constant and is the only parameter needed for the \gls{admm}. To be consistent with other literature that cover algorithms based on \gls{admm}, the penalty terms for the complicating constraints are written in a second order norm\footnote{~The norm formulation $\big\| . \big\|^2_2$ can be understood as the quadratic sum of the entries of the penalty term vector.}. This formulation is not necessary for the equation above because only scalars are used. Thus, the second order norm could be ignored and replaced with a simple quadratic term. However, due to the second order norm of the penalty terms of the relaxed complicating constraints, the first derivative of the objective function is not fixed anymore but continuous. This is also a necessary condition for the convergence of the algorithm. Still, the optimization problem in equation (\ref{eq:dom:fixed-duals}) is not decomposable because of the introduced dual variables. The problem is further relaxed by fixing the dual variable to given values $\overline{\lambda}$, $\overline{\mu}$, $\overline{\rho}$. The problem formulation becomes:

\begin{subequations}
	\begin{align}
		 \min \quad \sum_{t\in\mathcal{T}} \quad & \sum_{g\in\mathcal{G}}mc_g \cdot P_{g,t} + \sum_{s\in\mathcal{S}}mc_s \cdot (D_{s,t}+C_{s,t}) \label{eq:dom:final} \\
		 & + \overline{\lambda}_t \cdot \sum_{n \in \mathcal{N}} I_{n,t} \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\|\sum_{n \in \mathcal{N}} I_{n,t}\big\|^2_2 \nonumber \\
		 & +  \sum_{l \in \mathcal{L}} \quad \overline{\mu_{l,t}} \cdot (\sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} + U_{l,t} - \overline{f_l}) \nonumber \\
		 & \quad \qquad + \frac{\gamma}{2} \cdot \big\| \sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} + U_{l,t} - \overline{f_l} \big\|^2_2 \nonumber \\
		 & \quad \qquad + \overline{\rho_{l,t}} \cdot (\sum_{n \in \mathcal{N}} K_{l,t} - PTDF_{l,n} \cdot I_{n,t} - \overline{f_l}) \nonumber \\
		 & \quad \qquad + \frac{\gamma}{2} \cdot \big\|\sum_{n \in \mathcal{N}} K_{l,t} - PTDF_{l,n} \cdot I_{n,t} - \overline{f_l} \big\|^2_2 \nonumber \\[10pt]
		 \text{s.t. } \quad & 0 \leq P_{g,t} \leq \overline{p_g} && \forall g \in \set{G}, t \in \set{T}\\
		 & 0 \leq D_{s,t} \leq \overline{p_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq C_{s,t} \leq \overline{p_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq E_{s,t} \leq \overline{e_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & E_{s,t} - E_{s,t-1} - C_{s,t} + D_{s,t} = 0 && \forall s \in \set{S}, t \in \set{T}
	\end{align}
\end{subequations}

% TODO Add reference for ADMM explanation
Because of the product of the decision variable $P_{\mathcal{G},\mathcal{T}}$, $D_{\mathcal{S},\mathcal{T}}$ and $C_{\mathcal{S},\mathcal{T}}$ in all penalty terms, the optimization model is still not decomposable. At this step, the \gls{admm} comes into action and provides a possibility to solve the problem in a decomposable way. As written in \ref{admm}, \gls{admm} fixes each decision variable to the previous iteration value. Thus, one is finally able to derive the generator and storage subproblem. Out of simplicity, the over-line symbol on the dual variables is omitted in the next equations.


\subsubsection*{Generator Subproblem}

In the following, the optimization model for a specific generator $g$ is derived. The problem is only optimized by the decision variable $P_{g,\mathcal{T}}$ of this generator and the corresponding slack variables of the power flow constraint. With the help of \gls{admm}, decision variables $D_{\mathcal{S},\mathcal{T}}$ and $C_{\mathcal{S},\mathcal{T}}$ are fixed to the values of the previous iteration. The power output of all other generators $P_{g' \in \mathcal{G}\setminus g,\mathcal{T}}$ is fixed too. Any constraint related to these variables can be removed. Another parameter $v$ is added to the problem formulation that indicates the iteration number. Obviously, for decision variable $P_{g,\mathcal{T}}$ one takes the current iteration number $v$ while for the storages and other generators one takes the previous iteration $v-1$. The first derivative of the objective function shows that the objective function can be further simplified by removing terms related to $P_{g' \in \mathcal{G}\setminus g,\mathcal{T}}$, $D_{\mathcal{S},\mathcal{T}}$ and $C_{\mathcal{S},\mathcal{T}}$. The penalty terms can not be further simplified because of the second order norm. The optimization model for a single generator yields:

% P_{g,t}^v + \sum_{g'=g\notin\mathcal{G}}P_{g',t}^{v-1}  + \sum_{s\in\mathcal{S}}(D_{s,t}^{v-1} - C_{s,t}^{v-1}) - d_{n,t}
\begin{subequations}
	\begin{align}
		 \min \quad \sum_{t\in\mathcal{T}} \quad & mc_g \cdot P_{g,t}^v + \lambda_t^v \cdot P_{g,t}^v \label{eq:sub:gen}\\
		 & + \frac{\gamma}{2} \cdot \big\| \sum_{n \in \mathcal{N}} I_{n,t} \big\|^2_2 \nonumber \\
		 & + \sum_{l \in \mathcal{L}} \quad \mu_{l,t}^v \cdot \sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot P_{g,t}^v \nonumber \\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\| \sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} + U_{l,t}^v - \overline{f_l} \big\|^2_2 \nonumber \\
		 & \qquad \qquad - \rho_{l,t}^v \cdot \sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot P_{g,t}^v \nonumber \\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\| \sum_{n \in \mathcal{N}} K_{l,t}^v - PTDF_{l,n} \cdot I_{n,t} - \overline{f_l} \big\|^2_2 \nonumber \\[10pt]
		 \text{s.t.} \quad & 0 \leq P_{g,t}^v \leq \overline{p_g} && \forall t \in \set{T}
	\end{align}
\end{subequations}

The term inside of the brackets in the second line of equation (\ref{eq:sub:gen}) is once again the energy balance constraint. However, the power output of the other generators and storages is not a variable anymore but a parameter that is fixed to the previous iteration values'. Hence, the power output of the specific generator $P_{g,t}$ can be excluded from the sum. Then, the injection of the node $\breve{n}$, the generator is located at, can be formulated as:
 
 \begin{equation}
	I_{\breve{n},t} = P_{g,t}^v + \sum_{g'\in\mathcal{G}_{\breve{n}} \setminus g}p_{g',t}^{v-1} + \sum_{s\in\mathcal{S}_{\breve{n}}}(d_{s,t}^{v-1}-c_{s,t}^{v-1})-d_{\breve{n},t}
	\label{eq:injection:decentralized}
\end{equation} 
 
 The power generation terms of the other units are written in lower case to match the notation of parameters. Be aware that $d_{s,t}^{v-1}$ and $d_{\breve{n},t}$ are not the same. The first term depicts the discharge power output of a storage at node $\breve{n}$. The latter stands for the nodal demand of node $\breve{n}$. Equation (\ref{eq:injection:decentralized}) can be then inserted in the sum of all nodal injections for a specific time step $t$:
 
 \begin{equation}
 	\sum_{n \in \mathcal{N}} I_{n,t} = I_{\breve{n},t} + \sum_{n \in \mathcal{N} \setminus \breve{n}} \quad \sum_{g\in\mathcal{G}_n}p_{g',t}^{v-1} + \sum_{s\in\mathcal{S}_n}(d_{s,t}^{v-1}-c_{s,t}^{v-1})-d_{n,t}
 \end{equation}
 
 As for now, the specific generator needs to know the previous dispatch of all other units to compute the injection. This is in contradiction to the aim of this thesis to create a decentralized framework in which sensitive information is not shared with other participants. That includes the power dispatch of the previous iteration. To overcome the problem, the coordinating algorithm provides the sum of nodal power outputs for the other generators and storages in the network. The sum of the previous iteration power values' of all generators at a node $n$ and a time step $t$ is denoted as $\Theta_{n,t}$ and can be expressed as:
 
 \begin{equation}
 	\Theta_{n,t} = \sum_{g\in\mathcal{G}_{n}}P_{g,t}^{v-1}
 \end{equation}
 
 The same applies to the discharge and charge power values of the storages in the network. $\Phi_{n,t}$ depicts the sum of the previous discharge power values' of all storages at node $n$ and time step $t$ and $\Psi_{n,t}$ depicts the charging sum respectively. The corresponding equations are as follows:
 
\begin{equation}
	\Phi_{n,t} = \sum_{s\in\mathcal{S}_n}D_{s,t}^{v-1}
\end{equation}

\begin{equation}
	\Psi_{n,t} = \sum_{s\in\mathcal{S}_n}C_{s,t}^{v-1}
\end{equation}
 
 Using these values prevents the fact that the specific generators needs to know the actual power dispatch of the other participants. Since the power output of the specific generator $g$ is also included in $\Theta_{\breve{n},t}$, one has to subtract the power output from the last iteration of the specific generator from the sum. Thus, the sum of all nodal injections for the specific generator $g$ at node $\breve{n}$ becomes: 

 \begin{align}
 	\sum_{n \in \mathcal{N}} I_{n,t} &= P_{g,t}^v + \Theta_{\breve{n},t} - P_{g,t}^{v-1} + \Phi_{\breve{n},t} - \Psi_{\breve{n},t} - d_{\breve{n},t} \\
 	& + \sum_{n \in \mathcal{N} \setminus \breve{n}} \Theta_{n,t} + \Phi_{n,t} - \Psi_{n,t} - d_{n,t} \nonumber
 \end{align}
 
 The optimization model in (\ref{eq:sub:gen}) is further rearranged by summarizing the terms including the dual variables $\rho_{l,t}$ and $\mu_{l,t}$. In addition, a penalty terms for the decision variables are introduced. In the optimality point, these penalty terms become zero. Subsequently, they also contribute to a faster convergence. The penalty term for the decision variable $P_{g,t}$ calculates the difference between the current iteration value and the last iteration value. Since the slack variables of the power flow constraint have to be the same for all subproblems at global optimum, the penalty term for these decision variables considers the average of all subproblems of the last iteration. The average value for the upper flow constraint is denoted as $\Upsilon_{l,t}$ and $\Gamma_{l,t}$ respectively. Finally, the generator subproblem becomes:
 
 \begin{subequations}
	\begin{align}
		 \min \quad \sum_{t\in\mathcal{T}} \quad & mc_g \cdot P_{g,t}^v \label{eq:sub:gen-final}\\
		 & + P_{g,t}^v \cdot (\lambda_t^v + \sum_{l \in \mathcal{L}} \sum_{n \in \mathcal{N}} (\mu_{l,t}^v - \rho_{l,t}^v) \cdot PTDF_{l,n}) \nonumber \\ 
		 & + \frac{\gamma}{2} \cdot \big\| P_{g,t}^v + \Theta_{\breve{n},t} - P_{g,t}^{v-1} + \Phi_{\breve{n},t} - \Psi_{\breve{n},t} - d_{\breve{n},t} \nonumber \\
		 & \qquad + \sum_{n \in \mathcal{N} \setminus \breve{n}} \Theta_{n,t} + \Phi_{n,t} - \Psi_{n,t} - d_{n,t} \big\|^2_2 \nonumber \\
		 & + \sum_{l \in \mathcal{L}} \quad \frac{\gamma}{2} \cdot \big\| \sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} + U_{l,t}^v - \overline{f_l} \big\|^2_2 \nonumber \\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\| \sum_{n \in \mathcal{N}} K_{l,t}^v - PTDF_{l,n} \cdot I_{n,t} - \overline{f_l} \big\|^2_2 \nonumber \\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\|U_{l,t}^v - \Upsilon_{l,t}  \big\|^2_2 \nonumber\\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\|K_{l,t}^v - \Gamma_{l,t}  \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot (P_{g,t}^v - P_{g,t}^{v-1})^2 \nonumber \\[10pt]
		 \text{s.t.} \quad & 0 \leq P_{g,t}^v \leq \overline{p_g} && \forall t \in \set{T}
	\end{align}
\end{subequations}

\subsubsection*{Storage Subproblem}

This section derives the optimization model for a specific storage $s$. The problem only includes decision variables $D_{s,t}$, $C_{s,t}$ of the storage $s$ and the corresponding slack variables of the power flow constraint. As for the generator subproblem, all other decision variables from the main optimization model are fixed to the values of the previous iteration. Thus, constraints related to generators or storages can be removed. \\

The derivation of the optimization model for the storage subproblem is nearly the same as for the generator. Therefore a detail description of the derivation is omitted and the reader is referred to the generator subproblem for further detail. If the previous iteration values for the generators and other storages as well as the penalty terms are added, the storage subproblem yields:

 \begin{subequations}
	\begin{align}
		 \min \quad \sum_{t\in\mathcal{T}} \quad & mc_s \cdot (D_{s,t}^v + C_{s,t}^v)\label{eq:sub:stor}\\
		 & + (D_{s,t}^v - C_{s,t}^v) \cdot (\lambda_t^v + \sum_{l \in \mathcal{L}} \sum_{n \in \mathcal{N}} (\mu_{l,t}^v - \rho_{l,t}^v) \cdot PTDF_{l,n}) \nonumber \\ 
		 & + \frac{\gamma}{2} \cdot \big\| \Theta_{\breve{n},t} + D_{s,t}^v + \Phi_{\breve{n},t} - D_{s,t}^{v-1} \nonumber \\
		 & \qquad \qquad - C_{s,t}^v - (\Psi_{\breve{n},t} - C_{s,t}^{v-1}) - d_{\breve{n},t} \nonumber \\
		 & \qquad \qquad + \sum_{n \in \mathcal{N} \setminus \breve{n}} \Theta_{n,t} + \Phi_{n,t} - \Psi_{n,t} - d_{n,t} \big\|^2_2 \nonumber \\
		 & + \sum_{l \in \mathcal{L}} \quad \frac{\gamma}{2} \cdot \big\| \sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} + U_{l,t}^v - \overline{f_l}\big\|^2_2 \nonumber \\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\| \sum_{n \in \mathcal{N}} K_{l,t}^v - PTDF \cdot I_{n,t} - \overline{K_l}\big\|^2_2\nonumber \\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\|U_{l,t}^v - \Upsilon_{l,t}  \big\|^2_2 \nonumber\\
		 & \qquad \qquad + \frac{\gamma}{2} \cdot \big\|K_{l,t}^v - \Gamma_{l,t}  \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot (D_{s,t}^v - D_{s,t}^{v-1} )^2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot (C_{s,t}^v - C_{s,t}^{v-1} )^2 \nonumber \\[10pt]
		 \text{s.t.} \quad & 0 \leq D_{s,t}^v \leq \overline{p_s} && \forall t \in \set{T} \\
		 & 0 \leq C_{s,t}^v \leq \overline{p_s} && \forall t \in \set{T}\\
		 & 0 \leq E_{s,t}^v \leq \overline{e_s} && \forall t \in \set{T}\\
		 & E_{s,t}^v - E_{s,t-1}^v - C_{s,t}^v + D_{s,t}^v = 0 && \forall t \in \set{T}
	\end{align}
\end{subequations}

\subsubsection*{Update Dual Variables}

After solving every subproblem, the dual variables of the complicating constraints have to be updated as well. The following equations describe the update process of each dual variable in the problem for one time step. In case of the dual variables for the power flow constraint, the equations are based on a single time step and a single transmission line.

\begin{subequations}
	\begin{align}
		\lambda_t^{v+1} &= \lambda_t^{v} + \gamma \cdot (\sum_{g\in\mathcal{G}}P_{g,t}^{v} + \sum_{s\in\mathcal{S}}D_{s,t}^{v} - \sum_{s\in\mathcal{S}}D_{s,t}^{v} - d_{n,t}) \label{eq:update-duals:lambda} \\
		\rho_{l,t}^{v+1} &= \rho_{l,t}^{v} + \gamma \cdot (\sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} + \overline{\Upsilon_{l,t}^v} - \overline{f_l}) \\
		\mu_{l,t}^{v+1} &= \mu_{l,t}^{v} + \gamma \cdot (\overline{\Gamma_{l,t}^v} - \sum_{n \in \mathcal{N}} PTDF_{l,n} \cdot I_{n,t} - \overline{f_l}) \label{eq:update-duals:mu}
	\end{align}
\end{subequations}

In the context of a decentralized framework, this task would be orchestrated by the coordinator. After updating the duals, the coordinator examines the convergence status of the dual variables. A dual variable is converged if the difference between the next and the current iteration is smaller than a predefined threshold $\epsilon$. The overall algorithm converges if all dual variables are converged. Then, an optimal solution for each subproblem could be found that are also optimal solutions for the global problem. If a single dual variable is not converged, the next iteration is started utilizing the updated dual variables. The coordinator communicates the updated duals along with the nodal information of the last iteration to all generators and storages. 


\subsubsection{Matrix Notation}
\label{sec:app:matrix}

It is often common to formulate optimization problems in a matrix notation. With this notation it is much easier to understand multidimensional optimization problems. As for this thesis, several dimensions like time, nodes, lines are included. Thus, it would be beneficial for the reader to refer to the matrix notation if anything is unclear. In addition, \citet{boyd2010} also uses matrix notation to explain the \gls{admm}. Typically, \gls{admm} solves optimization problems in the form of:

\begin{subequations}
	\begin{align}
		\min{(x, z)} \quad & f(x) + g(z) \label{eq:admm:gen}\\[10pt]
		\text{s.t. } \quad & \vb{A}x + \vb{B}z = c \label{eq:admm:gen:con1}
	\end{align}
\end{subequations}

If applied to the formulations of the previous sections, $f(x)$ would be the generator costs and $g(z)$ the storage costs. The problem in (\ref{eq:admm:gen}) would be extended by the corresponding constraints for generators and storages. In addition, the power flow constraint would be added as another system constraint like equation (\ref{eq:admm:gen:con1}). The matrix notation can also be decomposed by applying the steps described in section (\ref{sec:app:dom}). \\

According to \citet{boyd2010}, \gls{admm} is often written in a shorter, so called scaled form. In this form, the linear and quadratic terms of the objective function are combined and the dual variables are scaled. This yields a much shorter formulation. As an example, the scaled dual variable of the energy balance constraint is derived. First, one defines a residual term of the energy balance constraint.

\begin{equation}
	\vb{r} = \vb{N_\mathcal{G}}*\vb{P} + \vb{N_\mathcal{S}}*(\vb{D} - \vb{C}) - \vb{d} = \vb{I}
\end{equation}

Here, $\vb{N_\mathcal{G}}$ and $\vb{N_\mathcal{S}}$ are the identity matrices indicating the node location of every generator and storage in the network. Inserting the residual term $r$ into the corresponding part of the optimization problem yields:

\begin{equation}
	\vb{\lambda} * \vb{r} + \frac{\gamma}{2} * || \vb{r} ||^2_2 = \frac{\gamma}{2} || \vb{r} + \frac{1}{\gamma}\vb{\lambda} ||^2_2 - \frac{1}{2\gamma}|| \vb{\lambda} ||^2_2 = \frac{\gamma}{2} || \vb{r} + \vb{\hat{\lambda}} ||^2_2 - \frac{\gamma}{2}|| \vb{\hat{\lambda}} ||^2_2 \label{eq:derivation_lambda_hat}
\end{equation}

The transformation is not very straight forward but allows to further simplify the  optimization problem. With $\vb{\hat{\lambda}} = \frac{1}{\gamma}*\vb{\lambda}$, one gets the scaled dual variable of $\vb{\lambda}$. Using the scaled dual variable makes the problem formulation much shorter because the last term $- \frac{\gamma}{2}|| \vb{\hat{\lambda}} ||^2_2$ of equation (\ref{eq:derivation_lambda_hat}) does not contain any optimization variable. Hence, this term can be removed. The other dual variables can be replaced respectively. In the following, the generator subproblem and the storage subproblem are formulated using the scaled form of the \gls{admm}.

\subsubsection*{Generator Subproblem}

The generator costs in matrix notation are formulated as follows:

\begin{subequations}
	\begin{align}
		f(x) &= f(\vb{P}) = \vb{P}^T \cdot \vb{mc}\\
		& = \begin{bmatrix}
			P_{g_1,t_1} & \dots & P_{g_n,t_1} \\
			\vdots & \ddots & \vdots \\
			P_{g_1,t_n} & \dots & P_{g_n,t_n}
		\end{bmatrix} \cdot \begin{bmatrix}
			mc_{g_1} \\
			\vdots \\
			mc_{g_n}
		\end{bmatrix}
	\end{align}
\end{subequations}

The matrix of the power generation values is transposed to allow matrix multiplication. If this formulation is applied to the generator optimization problem of equation (\ref{eq:sub:gen-final}), the matrix notation yields:

 \begin{subequations}
	\begin{align}
		 \min \quad & \vb{P}^v \cdot mc \\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{P}^v + \vb{\Theta} - \vb{P}^{v-1} + \vb{\Phi} - \vb{\Psi} - \vb{d} + \frac{\vb{\lambda}}{\gamma} \big\|^2_2 \\
		 & + \frac{\gamma}{2} \cdot \big\| PTDF \cdot \vb{I} + \vb{U} - \vb{\overline{f}} + \frac{\vb{\mu}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{K} - PTDF \cdot \vb{I} - \vb{\overline{f}} + \frac{\vb{\rho}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{U} - \vb{\Upsilon}  \big\|^2_2 \nonumber\\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{K} - \vb{\Gamma} \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{P}^v - \vb{P}^{v-1} \big\|^2_2 \nonumber \\[10pt]
		 \text{s.t.} \quad & \vb{0} \leq \vb{P} \leq \vb{\overline{p}}
	\end{align}
\end{subequations}

\subsubsection*{Storage Subproblem}

The storage costs in matrix notation are formulated as follows:

\begin{subequations}
	\begin{align}
		g(z) &= g(\vb{D}, \vb{C})\\
		& = \left(\vb{D} + \vb{C}\right)^T \cdot \vb{mc} \\
		& = \left(\begin{bmatrix}
			P_{s_1,t_1} & \dots & P_{s_n,t_1} \\
			\vdots & \ddots & \vdots \\
			P_{s_1,t_n} & \dots & P_{s_n,t_n}
		\end{bmatrix} + \begin{bmatrix}
			P_{s_1,t_1} & \dots & P_{s_n,t_1} \\
			\vdots & \ddots & \vdots \\
			P_{s_1,t_n} & \dots & P_{s_n,t_n}
		\end{bmatrix} \right) \cdot \begin{bmatrix}
			mc_{s_1} \\
			\vdots \\
			mc_{s_n}
		\end{bmatrix}
	\end{align}
\end{subequations}

If this formulation is applied to the storage optimization problem of equation (\ref{eq:sub:stor}), the matrix notation yields:

 \begin{subequations}
	\begin{align}
		 \min \quad & \left(\vb{D}^v + \vb{C}^v\right)^T \cdot mc\\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{\Theta} + \vb{D}^v + \vb{\Phi} - \vb{D}^{v-1} \nonumber \\
		 & \qquad \qquad - \vb{C}^v - (\vb{\Psi} - \vb{C}^{v-1}) - \vb{d} + \frac{\vb{\lambda}}{\gamma} \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\| PTDF \cdot \vb{I} + \vb{U} - \vb{\overline{f}} + \frac{\vb{\mu}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{K} - PTDF \cdot \vb{I} - \vb{\overline{f}} + \frac{\vb{\rho}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{U} - \vb{\Upsilon} \big\|^2_2 \nonumber\\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{K} - \vb{\Gamma} \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{D}^v - \vb{D}^{v-1}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} \cdot \big\| \vb{C}^v - \vb{C}^{v-1}\big\|^2_2 \nonumber \\[10pt]
		 \text{s.t.} \quad & \vb{0} \leq \vb{D} \leq \vb{\overline{p}} \\
		 & \vb{0} \leq \vb{C} \leq \vb{\overline{p}} \\
		 & \vb{0} \leq \vb{E} \leq \vb{\overline{e}}\\
		 & \vb{0} = \vb{E} - \vb{E}_{t-1} - \vb{C} + \vb{D}
	\end{align}
\end{subequations}

\subsubsection*{Update Dual Variables}

The equations to update the dual variables in matrix notation are as follows:

\begin{subequations}
	\begin{align}
		\lambda^{v+1} &= \lambda^{v} + \gamma \cdot (\vb{P}^v + \vb{D}^{v} - \vb{C}^v - \vb{d}) \\
		\rho^{v+1} &= \rho^{v} + \gamma \cdot (PTDF \cdot \vb{I} + \vb{\overline{\Upsilon^v}} - \vb{\overline{f}}) \\
		\mu^{v+1} &= \mu^{v} + \gamma \cdot (\vb{\overline{\Gamma^v}} - PTDF \cdot \vb{I} - \vb{\overline{f}})
	\end{align}
\end{subequations}


\subsection{Documentation of the Implementation in Julia}

This section provides the reader with a detailed description of how the previously stated optimization models are implemented in the programming language Julia\footnote{~\url{www.julialang.org}}. Hereby, Julia is used for this thesis because of its extremely fast execution times of scripts. Speed was one of the core design patterns when Julia was developed. Execution times are faster in comparison to other scripting languages like Python\footnote{~\url{www.python.org}} because Julia code is compiled to efficient native code with the help of the Low Level Virtual Machine. In addition, Julia is dynamically typed. This means that the programmer can define types, accelerating the execution time even more. The syntax of the language is easy to understand, making it possible for beginners to get started quickly. With over a thousand contributors, Julia has a large open-source community from which one can expect even more improvements in future times. Lastly, Julia provides a lot of interfaces to open-source and commercial optimization solvers like Gurobi\footnote{~\url{www.gurobi.com}}. These features supported the decision to implement the optimization models in Julia. \\

The section starts with a general overview of the code structure including information about subdirectories and the used open-source packages. Afterwards, the optimization model of the centralized approach is explained. Finally, the implementations for the decentralized optimization model are described.

\subsubsection{General Information}

Rather than defining everything in one Julia script, the approach was followed to divide the source code into separate units. This is a best practice in modern software development that allows to better understand the code and contributes to a more maintainable project. However, Julia is more a scripting language than an object-oriented language. Thus, one had to make some adjustments to provide a structured source code.\\ 

All Julia files are placed into the directory \path{src} that contains several subdirectories. Each of them has a different purpose. There is the \path{src/cases} directory that contains the Julia scripts for setting up a case study system. This directory can contain different case studies, making it possible to easily switch between different scenarios. Inside of \path{src/helpers} several helper scripts are defined that are used while running the decentralized optimization model. This includes methods to print results, calculating the $PTDF$ or several plotting functions to visualize the optimization results. All Julia scripts related to the decentralized optimization model are located in \path{src/optimization}. This compromises for example the modeling of the subproblems or functions to check the convergence of the problem. Lastly, all defined structures that are utilized in the source code are placed in \path{src/structures}. The structures scripts are also separated in corresponding categories, e.g. network elements like generators or penalty terms. There is one main script for running the centralized optimization model \path{src/opf_central_reference.jl} and one for the decentral optimization model using the \gls{admm} named \path{src/opf_admm_decentral.jl}. Both scripts include a case study from the before mentioned directory and the Julia script \path{src/imports.jl} that manages all imports from the subdirectories and the needed Julia packages.\\

All open-source packages that are used within the project are listed in the file \path{Project.toml}. This file is also used to create a reproducible environment for every user. To activate the environment, open the Julia package manager in the root directory of the project and run the command \lstinline[language=sh]{activate ADMM}. All necessary packages are then installed.\\

Gurobi is utilized as a solver as it is the fastest solver for optimization problems world-wide and provides with the Julia package Gurobi\footnote{~\url{www.juliapackages.com/p/gurobi}} an easy-to-use interface. The solver is used in combination with the Julia package JuMP that presents a modeling language for mathematical optimization problems and is introduced by \citet{dunning2017}. The package equips the user with several helper methods to formulate and solve optimization models. Another advantage of JuMP is that one can easily switch between solvers. Thus, it is possible to replace Gurobi with an open-source solver like Clp\footnote{~\url{www.github.com/coin-or/Clp}}. Lastly, the  Julia package PlotlyJS is used to create interactive plots.

\subsubsection{Centralized Optimization Problem}

This section illustrates the implementation of the centralized optimization model that is used as a reference model and presents the current state of the energy dispatch framework that is utilized in energy systems world-wide. The corresponding code is shown in the listing below. The linenumbers on the left hand-side are referenced in the following explanation.

\lstinputlisting[language=julia, caption=Implementation of the centralized optimization model, label=jl:com]{../src/opf_central_reference.jl}

First, the necessary packages and Julia scripts are imported in line \texttt{1}. Then the case study is included, providing all elements of the network with the relevant parameters. The code block between line \texttt{5} and \texttt{54} creates the optimization model. In the beginning of the block, helper indexes for all network elements are created. These are used in the later model equations. Afterwards, the $PTDF$ of the network is calculated using the helper function \lstinline[language=julia]{calculate_ptdf()} that is defined in \path{src/helpers/ptdf.jl} and is listed in \ref{sec:appendix:jl:helpers:ptdf} for further reference.  As a next step, the JuMP model object \lstinline[language=julia]{m} is initiated and the solver is set to Gurobi in line \texttt{16}. The variable \lstinline[language=julia]{gurobi_env} is defined in the import script \path{src/imports.jl} and suppresses multiple Gurobi license printings. Afterwards, the optimization variables are attached to the JuMP model. The created indexes are used to access the network elements that are stored in an array. The first dimension of all variables represents always the network element as shown in the matrix formulation of section (\ref{sec:app:matrix}). The second dimension represents the time index. The naming convention of the optimization variables reflect the variable names in the optimization equations from section (\ref{sec:app:math-form}). While declaring the variables, the corresponding bounds are set too. Hereby, one can make use of the implemented structures to access the corresponding parameters, e.g. setting the upper bound of the generator power output with the help of attribute \lstinline[language=julia]{max_generation}. This allows to reduce the number of constraints, making the optimization model more simple and faster. In lines \texttt{34} to \texttt{38} an expression is added to the model that calculates the injection at every timestep and node according to equation (\ref{eq:injection-term}) from section (\ref{sec:app:math-form}). The generation from either a generator or storage is included in the injection formulation of a specific timestep and node, if the node is equal to the node of the generating unit. This was implemented by using the ternary operator \lstinline[language=julia]{?:} and the attribute \lstinline[language=julia]{node} of the network element. The ternary operator serves as a short if-else-condition. Next, the objective function of the problem is defined in line \texttt{41} to \texttt{44}. This function sums up the product of the generation decision variables and marginal costs for all network elements and time steps. For storage network elements both discharging power and charging power are considered in the costs. The last part of the model setup introduces all constraints. Line \texttt{17} attaches the energy balance constraint to the model. This constraint uses the before defined expression for the injection term and makes sure that the sum of all node injections at a specific time step equals zero. Afterwards, the upper and lower line constraint limit is implemented. As explained in the previous section, this constraint was transformed into two equality constraints by introducing two slack variables respectively. Due to a Julia type error, the dot product between the $PTDF$ of one line and the injection term for one time step had to be calculated by summing up the single values of the dot product. Lastly, the energy level constraint of the storages is added to the model. This constraint makes sure that the current energy level consists of the energy level of the previous time step and the charging power minus the power that is withdrawn. The ternary operator is utilized again to set the initial energy level to zero for every storage in the network. In line \texttt{57}, the command is run to solve the optimization model \lstinline[language=julia]{m}. The rest of the implementation covers the output of the optimization variables and additional information like the system price or the line utilization.


\subsubsection{Decentralized Optimization Problem}

In the following, the implementations for the decentralized optimization model are explained. In comparison to the implementation of the central problem, this involves multiple methods and files. Thus, the implementation is not explained on a single file but rather explains the procedure of the algorithm that was established. An example that runs a decentralized optimal power flow can be found in the file \path{src/opf_admm_decentral.jl} and is shown in the listing below.

\lstinputlisting[language=julia, caption=Implementation of the decentralized optimization model]{../src/opf_admm_decentral.jl}

This is the top-level file that imports all scripts and the desired case study. Then, the \lstinline[language=julia]{admm} object is created using the structure defined in \path{src/helpers/admm.jl} that is also listed in \ref{sec:appendix:jl:structures:admm}. A custom constructor was written for this structure because the majority of the attributes are initialized with default values. The constructur also calculates the $PTDF$ that is then accessible through the corresponding attribute. See line \texttt{23} to \texttt{63} in \ref{sec:appendix:jl:structures:admm} for further reference. Only the network elements and the damping parameter $\gamma$ are necessary for the initialization of the \lstinline[language=julia]{admm} object. The whole optimization algorithm is started  in line \texttt{7} with a single command called \lstinline[language=julia]{run!(admm)}.\\

All files related to the optimization implementations are located in the directory \path{src/optimization}. Thus, the implementation of the \lstinline[language=julia]{run!(...)} method is defined in the file \path{src/optimization/run.jl} and represents the entry point into the decentralized algorithm framework. The method is shown in listing (\ref{jl:run}). It orchestrates the whole optimization algorithm that runs as long as the algorithm is not converged. Hence, in line \texttt{2} a while loop is established that checks the convergence of the algorithm after each iteration.

\lstinputlisting[language=julia, firstline=1, lastline=5, caption=Top-level method to orchestrate the decentralized algorithm, label=jl:run]{../src/optimization/run.jl}

The attribute \lstinline[language=julia]{convergence} is of type \lstinline[language=julia]{Convergence} that is defined in \path{src/structures/convergence.jl} and shown in \ref{sec:appendix:jl:structures:convergence}. The structure includes the current convergence status of all dual variables and their corresponding residual values. A dual variable is converged if the residual term is smaller than an error term $\epsilon$. The attribute \lstinline[language=julia]{all} of the \lstinline[language=julia]{Convergence} structure is used to determine the convergence of the whole algorithm. If all duals are converged, then the algorithm is converged and the attribute is set to true. In line \texttt{3} of listing (\ref{jl:run}), the iteration calculation is started, which consists of three steps. First, it optimizes all subproblems and prints the corresponding generations results to the console. Afterwards, the dual variables $\lambda_{t}^v$, $\mu_{l,t}^v$ and $\rho_{l,t}^v$ are updated and the convergence of the algorithm is checked. If not converged, the algorithm continues with the next iteration. The implementation of the iteration calculation can be found in (\ref{sec:appendix:jl:optimization:calculate-iteration}). In the following, the before mentioned steps are explained in more detail.

\subsubsection*{Optimize all Subproblems}

The method \lstinline[language=julia]{optimize_all_subproblems!(...)} is defined in the file \path{src/optimization/subproblems.jl} and can be found in (\ref{sec:appendix:jl:optimization:optimize-all-subproblems}). It does two things. First, it optimizes all storage and generator subproblems and concatenates the results into a dictionary. Then, this dictionary is used to create the \lstinline[language=julia]{result} object that is attached to the \lstinline[language=julia]{admm} object. Both optimization methods for the subproblems are defined in \path{src/optimization/subproblems.jl}. Be aware that both methods can have the same name since the arguments of the methods are different. This is also a design pattern to shorten method names in Julia. The optimization method to solve a generator subproblem is covered first. The corresponding implementation is listed in (\ref{jl:sub-gen}).

\lstinputlisting[language=julia, firstline=19, lastline=105, caption=Method to optimize a single generator subproblem,label=jl:sub-gen]{../src/optimization/subproblems.jl}

The layout of the function is similar to the implementation of the centralized problem in listing (\ref{jl:com}). First, the JuMP model instance \lstinline[language=julia]{sub} is initiated. Hereby, the name refers to the fact that the optimization problem is a subproblem of the whole decentralized optimal power flow. Next, the optimization variables are created. The variable names resemble once again the terms in the equations of section \ref{sec:app:math-form}. In comparison to the implementation of the centralized algorithm, the decision variable $P$ only depends on the time index. Before the injection expression is added to the model instance, the results from the previous iteration are retrieved from the \lstinline[language=julia]{admm} object in line \texttt{16} and \texttt{19}. This is done with the help of two functions that are defined in the file \path{src/helpers/results.jl}. Both functions make sure that in the first iteration, in which no previous results exist, a zero vector for the corresponding variables is returned. Otherwise, one could easily access the previous iteration results from the \lstinline[language=julia]{admm} object itself. The created variables are then used in the injection expression. As for the centralized problem, the ternary operator is used to determine if the node of the injection term equals the node at which the generator is located. If so, the generation decision variable is added to the injection term and the previous generation result is subtracted from the generation node result as written in section \ref{sec:app:dom}. The \lstinline[language=julia]{admm} object includes a dictionary attribute \lstinline[language=julia]{node_id_to_demand} that is utilized in the injection expression to access the nodal demand by the id of the node. As a next step, the penalty terms for the complicated constraints and the slack variables are added to the JuMP model in line \texttt{39}. Since both the generator and storage subproblem have the same penalty terms, a method called \lstinline[language=julia]{add_penalty_terms!(...)} was created that can be found in the file \path{src/optimization/penalty_terms.jl} and is listed in \ref{sec:appendix:jl:optimization:add-penalty-terms}. The method attaches the penalty terms as expressions to the model instance \lstinline[language=julia]{sub}. Hereby, the norm formulation from section \ref{sec:app:dom} is applied. Thus, the penalty term expression only depends on the time index. As for the slack decision variables of the subproblems, the average value from all subproblems is included in the penalty term. Similar to the method for the generation and node results from the previous iteration, a function is used to get the average value for the slack variables from the previous iteration. This function is defined in the result helper file that was mentioned before and returns a zero vector in the first iteration. The objective function of the generator problem is attached to the model instance in line \texttt{45} of listing (\ref{jl:sub-gen}). This equation reflects equation (\ref{eq:sub:gen-final}) of section \ref{sec:app:dom} with one exception. The factors before the penalty terms are different, see for example line \texttt{59}. This is due to the fact that equation (\ref{eq:sub:gen-final}) represents a general problem, whereas the objective function of the model instance \lstinline[language=julia]{sub} stands for a specific implementation. See the section \ref{sec:res} for further reference. Once again, the dot product between the $PTDF$ and the dual variables of the power flow constraint is implemented by summing up the entries of the vector due to a Julia type error. Adding the objective function to the model instance concludes the model setup and the model can be optimized in line \texttt{68}. After solving the problem, the values for the penalty terms are clustered in a corresponding structure that is defined in the file \path{src/structures/penalty_terms.jl}. Lastly, the result object of the generator is created. The advantage here is that one can easily access the optimization results from the generator with the help of the structure \lstinline[language=julia]{ResultGenerator} that is defined in the file \path{src/structures/results.jl}. See \ref{sec:appendix:jl:structures:results} for further reference. Returning the result object is the last step of the method. Then, the optimization of a single generator subproblem is finished.\\

Since the storage subproblem is implemented in the same fashion as the generator subproblem, a detailed description is omitted here. The only difference between the two implementations are the decision variables and the fact that the storage problem includes another constraint to ensure the consistence of the energy level. The implementation of the \lstinline[language=julia]{optimize_subproblem(storage::Storage)} method can be found in \ref{sec:appendix:jl:optimization:sub-storage} for further detail.\\

The last step of the iteration calculation is the concatenation of all subproblem results. The returned generator or storage result objects are stored in a dictionary that is then used to create the result object of the whole algorithm. See line \texttt{6} to \texttt{14} in \ref{sec:appendix:jl:optimization:calculate-iteration}. The corresponding structures \lstinline[language=julia]{Result} can be found in \path{src/structures/results.jl}. For the result structure of the algorithm a custom constructor is used whose only parameter is a dictionary containing all subproblem results indexed by the network element. The constructor then calculates all relevant information for the iteration like the total costs of the iteration, the nodal injection values or the line utilization. It also sets up a dictionary in which the results for each node are stored that are represented by the structure \lstinline[language=julia]{ResultNode} that is also defined in the file mentioned above. These node results are used to access the information about the last iteration values to calculate the penalty term of the system balance. Another important information are the average values for the upper and lower flow slack variables that are needed to set up the flow penalty terms and can be accessed by the attributes \lstinline[language=julia]{avg_U} and \lstinline[language=julia]{avg_K} respectively.

\subsubsection*{Update Dual Variables}

The next step of the iteration calculation involves the updating process of the dual variables $\lambda_{t}^v$, $\mu_{l,t}^v$ and $\rho_{l,t}^v$, see line \texttt{7} in (\ref{sec:appendix:jl:optimization:calculate-iteration}). The implementation of the update process is defined in \path{src/optimization/update_duals.jl} and consists of a main function \lstinline[language=julia]{update_duals!(...)} that handles the update of each dual variable. Since Julia does not provide the functionality of private functions, the update functions of each dual variable are marked with a double underscore. This a regular used convention to show that these functions should not be called anywhere else in the project. Updating a single dual variable does not make sense and should be avoided. Listing (\ref{jl:update-all-duals}) shows the implementation of all updating methods for the dual variables.

\lstinputlisting[language=julia, caption=Implementation of the dual updates, label=jl:update-all-duals]{../src/optimization/update_duals.jl}

Each update method for the dual variable resembles equations (\ref{eq:update-duals:lambda}) to (\ref{eq:update-duals:mu}). As for $\lambda_{t}^v$, the overall system balance of the current iteration is calculated utilizing the result object that was created after solving all subproblems. The updated lambda ($\lambda_{t}^{v+1}$) is then added to the attribute \lstinline[language=julia]{lambdas} of the \lstinline[language=julia]{admm} object in line \texttt{14}. Thus, the next iteration can access the updated lambda as the last element in the array. The dual variables for the power flow constraint are updated in the same fashion. Only the injection term of the current iteration and the corresponding average slack variable are needed to calculate the dual power flow variables of the next iteration. The injection term is retrieved from the result object of the current iteration. As for the average slack variables of all subproblems, the helper function from the penalty terms is utilized again, see for example line \texttt{19}. Both update functions for the dual power flow variables include an adaption in line \texttt{24}/\texttt{25} and \texttt{36}/\texttt{37}. The reason for this is explained in more detail in section \ref{sec:res}. Finally, the calculated and adjusted dual power flow variables are added to the corresponding attribute of the \lstinline[language=julia]{admm} object in order to utilize the duals in a next iteration.

\subsubsection*{Check Convergence Status}

The last step of the iteration calculation implies the convergence check. As already explained, the algorithm converges if the difference between the next and the current iteration values of all dual variables is smaller than a predefined threshold $\epsilon$. Only if all residuals of the dual variables are within that threshold, the algorithm converges. Since all duals variables are stored in an array, the calculation of the residual between the next and the current iteration is straightforward. The implementation of the convergence check can be found in \path{src/optimization/convergence.jl} and is listed below.

\lstinputlisting[language=julia, caption=Implementation of the convergence check]{../src/optimization/convergence.jl}

The already mentioned threshold $\epsilon$ is defined in line \texttt{2}. It does not make sense to calculate the residuals of the duals in the first iteration of the algorithm. Thus, in line \texttt{3} the method checks the current iteration number against the initialization value of one. This is sufficient enough because the iteration number can only take values greater than 1. As a consequence, the convergence structure of the \lstinline[language=julia]{admm} object is not updated in the first iteration. In any other iteration cycle, the residuals of each dual variable are calculated as written above, see for example line \texttt{5}. The convergence structures provides an attribute to store the residual of each iteration for further analysis. Thus, the calculated residuals are added to the corresponding array of the convergence structure. Next, each entry of the residual matrix of the duals is compared against the defined threshold in lines \texttt{14} to \texttt{16}. This is implemented by using the dot syntax of Julia in front of the less operator. The function \lstinline[language=julia]{all(...)} tests whether all entries of the residual matrix are less than the threshold. As soon as one entry is bigger than the threshold the function returns \lstinline[language=julia]{false}. Finally, the convergence of the whole algorithm can be determined using the \lstinline[language=julia]{all(...)} again to check if all duals are converged. The last part of the method checks the convergence status and increases the iteration number by one if the algorithm is not converged. In addition, the convergence status is printed to the console.








































