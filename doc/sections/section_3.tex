\chead{\textit{Application}}  				
\section{Application}

%TODO Write introduction to chapter

\subsection{Modeling Framework}
\label{sec:app:mod-framework}

This section introduces the reader to all relevant information about the modelling framework that is used to model a real-life application. The modelling framework has to cover certain requirements. Firstly, there should be generators that produce electrical power. The power output is only limited by the maximum capacity of the generator. There exist no ramping constraints or minimum up- and down-times. Each generator has marginal costs and is connected to a specific node. To depict these requirements in Julia, a generator structure was implemented as you can see in the following code snippet. In addition to the stated requirements, the structure also contains a colour and a name. These attributes are mainly used for evaluation reasons and are not important for modelling purposes. 

\lstinputlisting[language=julia, firstline=7, lastline=13, caption=Structure for a node element]{../src/structures/network_elements.jl}

Another part of the modelling framework is a storage unit. Storages should be able to store a surplus of energy as well as deliver electrical power by discharging their capacity. The power input and output is also limited. In addition, a storage unit should only be able to store a certain amount of energy. This is depicted by the storage level. As generators, storages have specific marginal costs for charging and discharging and are connected to a specific node. A Julia structure was implemented respectively.\\

As written before, generators and storages are located at network nodes. These nodes have a specific demand that should be matched by the output of the generating units. For modelling purposes, it is also crucial to define a slack node to compensate the power flow balance. The node structure was implemented as follows:

\lstinputlisting[language=julia, firstline=1, lastline=5, caption=Structure for a generator element]{../src/structures/network_elements.jl}

The last element of the framework is a transmission line. This element connects nodes and enables the exchange of energy. Transmission lines are characterized by their maximum capacity and their susceptance value. A Julia structure was also implemented for this network element.\\

Lastly, the modelling framework has to consider multi-periods. This is crucial since without multi periods, it would not make sense to include storages into the system.\\

All structures are defined in \path{src\structures\network_elements.jl} and can be found in \ref{sec:appendix:jl:ne}.


\subsection{Mathematical Formulations}
\label{sec:app:math-form}

As written in the introduction, the aim of this thesis is to develop a framework to minimize the total system costs of a electrical network in a decentralized manner. This means that the costs are optimized without a central entity. Thus, the generating units are able to derive their own optimal decisions without releasing sensible information like their marginal costs. This section presents the mathematical formulations of the optimization problem. Since the solution of the decentralized problem will be compared with the solution of the centralized problem and the decentralized problem is based on the centralized problem, the centralized optimization model is introduced first.

\subsubsection{Centralized Optimization Problem}

The total system costs of a electrical network are the sum of generation costs of all participating units over all time steps. With regard to the modeling framework, this means that the system costs are composed of the generator costs and the storage costs. The centralized optimization problem can be formulated as follows:

\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}}\sum_{g\in\mathcal{G}}c_g*P_g(t) + \sum_{s\in\mathcal{S}}c_s*(P_s^d(t)+P_s^c(t))\\
		 \text{s.t. } \quad & 0 \leq P_g(t) \leq \overline{P_g} && \forall g \in \set{G}, t \in \set{T} \label{eq:com:con:max-g}\\
		 & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:max-sd}\\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:max-sc}\\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:s-level-max}\\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:s-level}\\
		 & I_n(t) = \sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t) = 0 && \forall t \in \set{T}, n \in \set{N} \label{eq:com:con:eb}\\
		 & -\overline{L_l} \leq PTDF * I_n(t) \leq \overline{L_l} && \forall l \in \set{L}, t \in \set{T}, n \in \set{N} \label{eq:com:con:pf}
	\end{align}
\end{subequations}

Hereby, $\mathcal{G}$ represents the set of generators and $\mathcal{S}$ the set of storage respectively. $\mathcal{T}$ includes all considered timesteps. The optimization problem is constrained to meet the requirements written in section (\ref{sec:app:mod-framework}). First of all, equation (\ref{eq:com:con:max-g}) limits the maximum output of all generators where $\overline{P_g}$ is the maximum power generation of the considered generator. Equations (\ref{eq:com:con:max-sd}) and (\ref{eq:com:con:max-sc}) set the boundaries of all storages and equation (\ref{eq:com:con:s-level-max}) ensures that the storage level of all storages remains between zero and the maximum storage level $\overline{E_s}$. The storage level at a specific time step can be calculated as follows:

\begin{equation}
	\label{eq:storage-level}
	E_s(t) = E_s(t-1) + P_s^c(t) - P_s^d(t)
\end{equation}

To get a consistent form of all constraints, equation (\ref{eq:storage-level}) is rearranged to equal zero and integrated in the optimization problem as equation (\ref{eq:com:con:s-level}). Hereby, $P_s^c(t)$ denotes the charging output of a storage $s$ at a timestep $t$ and $P_s^d(t)$ the discharging output. Equation (\ref{eq:com:con:eb}) is the so called energy balance. This constraint ensures that the demand at every node and every time step is met. The energy balance is also referred to as the injection at node $n$ at time step $t$. The injection term is used in the last constraint (\ref{eq:com:con:pf}) that establishs the network constraints. Here, the power flows on each transmission line are limited by the maximum line capacity $\overline{L_l}$. The line utilization for each transmission line is calculated by multiplying the \gls{ptdf} with the injection term $I_n(t)$.\\

	%TODO Explain PTDF, see maybe document from EMOD.
	
To solve the optimization problem, all relevant information has to be shared with the central entity. In the example above this includes marginal costs and the maximal capacities of the generating units. The central entity is then able to derive the optimal dispatch plan that minimizes the total system costs and informs the generating units about their generation schedule. Thus, the generating units are not able to optimize their decision on their own because the central entity is needed for coordination.	

\subsubsection{Decentralized Optimization Problem}
\label{sec:app:dom}

% TODO Add reference for ADMM explanation
The generating units in the centralized optimization problem are not able to optimize on their own because a central entity is needed to coordinate the system constraints (\ref{eq:com:con:eb}) and (\ref{eq:com:con:pf}). These constraints prevent that the solution is obtained by optimizing per generating unit because both include all decision variables of the optimization problem. This is the reason why these constraints are called complicating constraints. If resolved, it would be possible to derive the optimal dispatch plan per generating unit and without sharing sensible information like marginal costs. As written in \ref{admm}, the \gls{admm} provides a technique to resolve these constraints, making the problem decomposable and thus enables the path to a decentralized mechanism. \gls{admm} is only working for equality constraints. Thus, the power flow inequality constraint (\ref{eq:com:con:pf}) is transformed into two equality constraints by introducing two slack variables $R^{ref}_l$ and $R^{cref}_l$ for each tranmission line $l$. The optimization problem evolves to the following:

\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}}\sum_{g\in\mathcal{G}}c_g*P_g(t) + \sum_{s\in\mathcal{S}}c_s*(P_s^d(t)+P_s^c(t)) \label{eq:dom:relaxed-constraints}\\
		 \text{s.t.} \quad & 0 \leq P_g(t) \leq \overline{P_g} && \forall g \in \set{G}, t \in \set{T} \\
		 & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall s \in \set{S}, t \in \set{T} \\
		 & I_n(t) = \sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t) = 0 && \forall t \in \set{T}, n \in \set{N} \label{eq:dom:injection-term} \\
		 & PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l} = 0 && \forall l \in \set{L}, t \in \set{T}, n \in \set{N} \label{eq:dom:con:pf-upper} \\
		 & R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l} = 0 && \forall l \in \set{L}, t \in \set{T}, n \in \set{N} \label{eq:dom:con:pf-lower}
	\end{align}
\end{subequations}

The slack variable $R_l^{ref}$ ensures that the upper bound of the transmission line capactiy is kept, while slack variable $R_l^{cref}$ ensures the lower limit. Both variables are added as additional decision variables. Instead of two complicating constraints, one has to handle three complicating constraints. If these constraints are relaxed, the main problem decomposes into a generator and a storage subproblem.\\

Relaxing the complicating variables is done by implementing a max-min problem using the dual variables of the complicated constraints. Hereby, $\lambda$ is the dual of the energy balance constraint, $\mu$ and $\rho$ are the duals of the upper and lower power flow constraint respectively. Since the objective function is a linear cost function, \gls{lr} is not applicable. Thus, the complicated constraints are relaxed by applying \gls{alr}. A penalty term for each dual variable is introduced. The penalty terms equal zero in the optimality point and contribute to a faster convergence. The optimization problem of (\ref{eq:dom:relaxed-constraints}) derives to:

\begin{subequations}
	\begin{align}
		\max{(\lambda, \mu, \rho)} \label{eq:dom:fixed-duals} \\
		 & \min \quad \sum_{t\in\mathcal{T}}\sum_{g\in\mathcal{G}}c_g*P_g(t) + \sum_{s\in\mathcal{S}}c_s*(P_s^d(t)+P_s^c(t)) \nonumber \\
		 & + \lambda * \left[\sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t)\right]\nonumber \\
		 & + \frac{\gamma}{2} * \left[\sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t)\right]^2 \nonumber \\
		 & + \mu * \left[PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l}\right] \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l}\right]^2 \nonumber \\
		 & + \rho * \left[R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l}\right]\nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l}\right]^2 \nonumber
	\end{align}
	\begin{align}
		 \text{s.t. } \quad & 0 \leq P_g(t) \leq \overline{P_g} && \forall g \in \set{G}, t \in \set{T}\\\
		 & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall s \in \set{S}, t \in \set{T}
	\end{align}
\end{subequations}

Variable $\gamma$ is a positive constant and is the only parameter needed for the \gls{admm}. Due to the quadratic terms of the relaxed complicating constraitns, the first derivatives of the objective function is not fixed anymore but continuous. This is also a necessary condition for the convergence of the algorithm. Still, the optimization problem in equation (\ref{eq:dom:fixed-duals}) is not decomposable because of the introduced dual variables. The problem is further relaxed by fixing the dual variable to given values $\overline{\lambda}$, $\overline{\mu}$, $\overline{\rho}$. The problem formulation becomes:

\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}}\sum_{g\in\mathcal{G}}c_g*P_g(t) + \sum_{s\in\mathcal{S}}c_s*(P_s^d(t)+P_s^c(t)) \label{eq:dom:final} \\
		 & + \overline{\lambda} * \left[\sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t)\right]\nonumber \\
		 & + \frac{\gamma}{2} * \left[\sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t)\right]^2 \nonumber \\
		 & + \overline{\mu} * \left[PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l}\right] \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l}\right]^2 \nonumber \\
		 & + \overline{\rho} * \left[R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l}\right]\nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l}\right]^2\nonumber \\
		 \text{s.t.} \quad & 0 \leq P_g(t) \leq \overline{P_g} && \forall g \in \set{G}, t \in \set{T}\\\
		 & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall s \in \set{S}, t \in \set{T}
	\end{align}
\end{subequations}

% TODO Add reference for ADMM explanation
Because of the product of the decision variable $P_{\mathcal{G}}$, $P_{\mathcal{S}}^d$ and $P_{\mathcal{S}}^c$ in all penalty terms, the optimization model is still not decomposable. At this step, the \gls{admm} comes into action and provides a possibility to solve the problem in a decomposable way. As written in \ref{admm}, \gls{admm} fixes each decision variable to the previous iteration value. Thus, one is finally able to derive the generator and storage subproblem. Out of simplicity, the overline symbol on the dual variables is omitted in the next equations.


\subsubsection*{Generator Subproblem}

In the following, the optimization model for a specific generator $g$ is derived. The problem is only optimized by the decision variable $P_{g}$ of this generator and the corresponding slack variables of the power flow constraint. With the help of \gls{admm}, decision variables $P_{\mathcal{S}}^d$ and $P_{\mathcal{S}}^c$ are fixed to the values of the previous iteration. The power output of all other generators $P_{g \notin \mathcal{G}}$ is fixed too. Any constraint related to these variables can be removed. Another parameter $v$ is added to the problem formulation that indicates the iteration number. Obviously, for decision variable $P_{g}$ one takes the current iteration number $v$ while for the storages and other generators one takes the previous iteration $v-1$. The first derivative of the objective function shows that the objective function can be further simplified by removing terms related to $P_{g \notin \mathcal{G}}$, $P_{\mathcal{S}}^d$ and $P_{\mathcal{S}}^c$. The penalty terms can not be further simplified because of the quadratic term. The optimization model for a single generator yields:

% When writing multi-line equations with the align, align* or aligned environments, the \left and \right commands must be balanced on each line and on the same side of &. The solution is to use "invisible" brackets to balance things out, i.e. adding a \right. at the end of the first line, and a \left. at the start of the second line after &:
\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}} c_g*P_g(v, t) + \lambda * P_g(v, t) \label{eq:sub:gen}\\
		 & + \frac{\gamma}{2} * \left[ P_g(v, t) + \sum_{g\notin\mathcal{G}}P_g(v-1,t) \right. \nonumber \\
		 & \qquad \left. + \sum_{s\in\mathcal{S}}(P_s^d(v-1, t)-P_s^c(v-1, t))-D_n(t)\right]^2 \label{eq:sub:gen:eb} \\
		 & + \mu * PTDF * P_g(v, t) \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(v, t) + R^{ref}_l(v, t) - \overline{L_l}\right]^2 \nonumber \\
		 & - \rho * PTDF * P_g(v, t) \nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - PTDF * I_n(v, t) - \overline{L_l}\right]^2\nonumber \\
		 \text{s.t.} \quad & 0 \leq P_g(v, t) \leq \overline{P_g} && \forall t \in \set{T}
	\end{align}
\end{subequations}

 The term inside of the brackets of equation (\ref{eq:sub:gen:eb}) is once again the injection formulation. In comparison to equation (\ref{eq:dom:injection-term}), the power output of the other generators and storages is not a variable anymore but a parameter. Hence, the power output of the specific generator $P_{g}$ is excluded from the sum.\\
 
 As for now, the specific generator needs to know the previous dispatch of all other units to compute the injection. This is in contradiction to the aim of this thesis to create a decentralized framework in which sensitive information is not shared with other participants. That includes the power dispatch of the previous iteration. To overcome the problem, the coordinating algorithm provides the summed power outputs of the other generators and storages. Using the sum prevents the fact that the specific generators needs to know the acutal power values. Since the power output of the specific generator is also included, one has to subtract the power output from the last iteration of the specific generator from the sum. \\
 
 The optimization model in (\ref{eq:sub:gen}) is further rearranged by summarising the dual variables. In addition, penalty terms for the decision variables are introduced. These penalty terms calculate the difference between the current iteration value and the last iteration value. Since the slack variables of the power flow constraint have to be the same for all subproblems, the penalty term of these decision variables is compared against the average value of the last iteration of all subproblems. In the optimality point, these penalty terms become zero. Subsequently, they also contribute to a faster convergence. Finally, the generator subproblem becomes:
 
 \begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}} c_g*P_g(v, t) \label{eq:sub:gen-final}\\
		 & + P_g(v, t) * (\lambda + (\mu - \rho) * PTDF) \nonumber \\ 
		 & + \frac{\gamma}{2} * \left[P_g(v, t) + \sum P_{\mathcal{G}}(v-1,t) - P_g(v-1, t) \right. \nonumber \\
		 & \qquad \left. + \sum P_{\mathcal{S}}^d(v-1, t) - \sum P_{\mathcal{S}}^c(v-1, t) - D_n(t)\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(v, t) + R^{ref}_l(v, t) - \overline{L_l}\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - PTDF * I_n(v, t) - \overline{L_l}\right]^2\nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{ref}_l(v, t) - \overline{R^{ref}_l}(v-1, t)  \right]^2 \nonumber\\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - \overline{R^{cref}_l}(v-1, t)  \right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[P_g(v, t) - P_g(v-1, t)\right]^2 \nonumber \\
		 \text{s.t.} \quad & 0 \leq P_g(v, t) \leq \overline{P_g} && \forall t \in \set{T}
	\end{align}
\end{subequations}

\subsubsection*{Storage Subproblem}

This section derives the optimization model for a specific storage $s$. The problem only includes decision variables $P_{s}^d$, $P_{s}^c$ of the storage $s$ and the corresponding slack variables of the power flow constraint. As for the generator subproblem, all other decision variables from the main optimization model are fixed to the values of the previous iteration. Thus, constraints related to generators or ther storages can be removed. \\

The derivation of the optimization model for the storage subproblem is nearly the same as for the generator. Therefore a detail decsription of the derivation is omitted and the reader is referred to the generator subproblem for further detail. If the previous iteration values for the generators and other storages as well as the penalty terms are added, the storage subproblem yields:

 \begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}} c_s*(P_s^d(v, t) + P_s^c(v, t))\label{eq:sub:stor}\\
		 & + (P_s^d(v, t) - P_s^c(v, t)) * (\lambda + (\mu - \rho) * PTDF) \nonumber \\ 
		 & + \frac{\gamma}{2} * \left[\sum P_{\mathcal{G}}(v-1,t) \right. \nonumber \\ 
		 & \qquad \left. + P_s^d(v, t) + \sum P_{\mathcal{S}}^d(v-1, t) - P_s^d(v-1, t) \right. \nonumber \\
		 & \qquad \left. - P_s^c(v, t) - (\sum P_{\mathcal{S}}^c(v-1, t) -  P_s^c(v-1, t)) - D_n(t)\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(v, t) + R^{ref}_l(v, t) - \overline{L_l}\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - PTDF * I_n(v, t) - \overline{L_l}\right]^2\nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{ref}_l(v, t) - \overline{R^{ref}_l}(v-1, t)  \right]^2 \nonumber\\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - \overline{R^{cref}_l}(v-1, t)  \right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[P_s^d(v, t) - P_s^d(v-1, t)\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[P_s^c(v, t) - P_s^c(v-1, t)\right]^2 \nonumber \\
		 \text{s.t.} \quad & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall t \in \set{T} \\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall t \in \set{T}\\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall t \in \set{T}\\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall t \in \set{T}
	\end{align}
\end{subequations}

\subsubsection{Matrix Notation}
\label{sec:app:matrix}

It is often common to formulate optimization problems in a matrix notation. With this notation it is much easier to understand multidimensional optimization problems. As for this thesis, several dimensions like time, nodes, lines are included. Thus, it would be benificial for the reader to refer to the matrix notation if anything is unclear. In addition, \citet{boyd2010} also uses matrix notation to explain the \gls{admm}. Typically, \gls{admm} solves optimization problems in the form of:

\begin{subequations}
	\begin{align}
		\min{(x, z)} \quad & f(x) + g(z) \label{eq:admm:gen}\\
		\text{s.t. } \quad & \vb{A}x + \vb{B}z = c \label{eq:admm:gen:con1}
	\end{align}
\end{subequations}

If applied to the formulations of the previous sections, $f(x)$ would be the generator costs and $g(z)$ the storage costs. The problem in (\ref{eq:admm:gen}) would be extended by the corresponding constraints for generators and storages. In addition, the power flow constraint would be added as another system constraint like equation (\ref{eq:admm:gen:con1}). The matrix notation can also be decomposed by applying the steps described in section (\ref{sec:app:dom}). \\

According to \citet{boyd2010}, \gls{admm} is often written in a shorter, so called scaled form. In this form, the linear and quadratic terms of the objective function are combined and the dual variables are scaled. This yields a much shorter formulation. As an example, the scaled dual variable of the energy balance is derived. First, one defines a residual term of the energy balance constraint.

\begin{equation}
	\vb{r} = \vb{N_\mathcal{G}}*\vb{P_\mathcal{G}} + \vb{N_\mathcal{S}}*(\vb{P_\mathcal{S}^d} - \vb{P_\mathcal{S}^c}) - \vb{D_\mathcal{N}} = \vb{I_\mathcal{N}}
\end{equation}

Here, $\vb{N_\mathcal{G}}$ and $\vb{N_\mathcal{S}}$ are the identity matrices indicating the node location of every generator and storage. Inserting the residual term $r$ into the corresponding part of the optimization problem yields:

\begin{equation}
	\vb{\lambda} * \vb{r} + \frac{\gamma}{2} * || \vb{r} ||^2_2 = \frac{\gamma}{2} || \vb{r} + \frac{1}{\gamma}\vb{\lambda} ||^2_2 - \frac{1}{2\gamma}|| \vb{\lambda} ||^2_2 = \frac{\gamma}{2} || \vb{r} + \vb{\hat{\lambda}} ||^2_2 - \frac{\gamma}{2}|| \vb{\hat{\lambda}} ||^2_2 \label{eq:derivation_lambda_hat}
\end{equation}

The transformation is not very straight forward but allows to further simplify the  optimization problem. With $\vb{\hat{\lambda}} = \frac{1}{\gamma}*\vb{\lambda}$, one gets the scaled dual variable of $\vb{\lambda}$. Using the scaled dual variable makes the problem formulation much shorter because the last term $- \frac{\gamma}{2}|| \vb{\hat{\lambda}} ||^2_2$ of equation (\ref{eq:derivation_lambda_hat}) does not contain any optimization variable. Hence, this term can be removed. The other dual variables can be replaced respectively. In the following the generator subproblem and the storage subproblem are formulated using the scaled form of the \gls{admm}.

\subsubsection*{Generator Subproblem}

The generator costs in matrix notation are formulated as follows:

\begin{subequations}
	\begin{align}
		f(x) &= f(\vb{P_\mathcal{G}}) = \vb{P_\mathcal{G}}^T * \vb{c_\mathcal{G}}\\
		& = \begin{bmatrix}
			P_{g_1}(t_1) & \dots & P_{g_n}(t_1) \\
			\vdots & \ddots & \vdots \\
			P_{g_1}(t_n) & \dots & P_{g_n}(t_n)
		\end{bmatrix} * \begin{bmatrix}
			c_{g_1} \\
			\vdots \\
			c_{g_n}
		\end{bmatrix}
	\end{align}
\end{subequations}

If this formulation is applied to the generator optimization problem of equation (\ref{eq:sub:gen-final}), the matrix notation yields:

 \begin{subequations}
	\begin{align}
		 \min \quad & \vb{P_g}^T * \vb{c}_g \\
		 & + \frac{\gamma}{2} * \big\| \vb{P_g} + \sum \vb{P_\mathcal{G}}(v-1) - \vb{P_g}(v-1) \nonumber \\
		 & \qquad + \sum \vb{P_\mathcal{S}^d}(v-1) - \sum \vb{P_\mathcal{S}^c}(v-1) - \vb{D_n} + \frac{\vb{\lambda}}{\gamma} \big\|^2_2 \label{eq:dom-matrix:eb} \\
		 & + \frac{\gamma}{2} * \big\| PTDF * \vb{I_n} + \vb{R^{ref}} - \vb{\overline{L}} + \frac{\vb{\mu}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{cref}} - PTDF * \vb{I_n} - \vb{\overline{L}} + \frac{\vb{\rho}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{ref}} - \vb{\overline{R^{ref}}}(v-1)  \big\|^2_2 \nonumber\\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{cref}} - \vb{\overline{R^{cref}}}(v-1) \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{P_g} - \vb{P_g}(v-1) \big\|^2_2 \nonumber \\
		 \text{s.t.} \quad & \vb{0} \leq \vb{P_g} \leq \vb{\overline{P_g}}
	\end{align}
\end{subequations}

Hereby, the matrices of the previous iteration values in equation (\ref{eq:dom-matrix:eb}) are summed up for all generators and storages, making these values only time-dependent. One should also note the norm formulation in the quadratic terms of the formulation. This norm is further examined in the result section of this thesis.

\subsubsection*{Storage Subproblem}

The storage costs in matrix notation are formulated as follows:

\begin{subequations}
	\begin{align}
		g(z) &= g(\vb{P_\mathcal{S}^d}, \vb{P_\mathcal{S}^c})\\
		& = \left(\vb{P_\mathcal{S}^d} + \vb{P_\mathcal{S}^c}\right)^T * \vb{c_\mathcal{S}} \\
		& = \left(\begin{bmatrix}
			P_{s_1}^d(t_1) & \dots & P_{s_n}^d(t_1) \\
			\vdots & \ddots & \vdots \\
			P_{s_1}^d(t_n) & \dots & P_{s_n}^d(t_n)
		\end{bmatrix} + \begin{bmatrix}
			P_{s_1}^c(t_1) & \dots & P_{s_n}^c(t_1) \\
			\vdots & \ddots & \vdots \\
			P_{s_1}^c(t_n) & \dots & P_{s_n}^c(t_n)
		\end{bmatrix} \right) * \begin{bmatrix}
			c_{s_1} \\
			\vdots \\
			c_{s_n}
		\end{bmatrix}
	\end{align}
\end{subequations}

If this formulation is applied to the storage optimization problem of equation (\ref{eq:sub:stor}), the matrix notation yields:

 \begin{subequations}
	\begin{align}
		 \min \quad & \left(\vb{P_s^d} + \vb{P_s^c}\right)^T * \vb{c_s}\\
		 & + \frac{\gamma}{2} * \big\| \sum \vb{P_\mathcal{G}}(v-1) \nonumber \\ 
		 & \qquad + \vb{P_s^d} + \sum \vb{P_\mathcal{S}^d}(v-1) - \vb{P_s^d}(v-1) \nonumber \\
		 & \qquad - \vb{P_s^c} - (\sum \vb{P_\mathcal{S}^c}(v-1) -  \vb{P_s^c}(v-1)) - \vb{D_n} + \frac{\vb{\lambda}}{\gamma} \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| PTDF * \vb{I_n} + \vb{R^{ref}} - \vb{\overline{L}} + \frac{\vb{\mu}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{cref}} - PTDF * \vb{I_n} - \vb{\overline{L}} + \frac{\vb{\rho}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{ref}} - \vb{\overline{R^{ref}}}(v-1)  \big\|^2_2 \nonumber\\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{cref}} - \vb{\overline{R^{cref}}}(v-1) \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{P_s^d} - \vb{P_s^d}(v-1)\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{P_s^c} - \vb{P_s^d}(v-1)\big\|^2_2 \nonumber \\
		 \text{s.t.} \quad & \vb{0} \leq \vb{P_s^d} \leq \vb{\overline{P_s}} \\
		 & \vb{0} \leq \vb{P_s^c} \leq \vb{\overline{P_s}} \\
		 & \vb{0} \leq \vb{E_s} \leq \vb{\overline{E_s}}\\
		 & \vb{0} = \vb{E_s} - \vb{E_s^{t-1}} - \vb{P_s^c} + \vb{P_s^d}
	\end{align}
\end{subequations}


\subsection{Documentation of the Implementation in Julia}

This section provides the reader with a detailed description of how the previously stated optimization models are implemented in the programming language Julia\footnote{~\url{www.julialang.org}}. Hereby, Julia is used for this thesis because of its extremely fast execution times of scripts. Speed was one of the core design patterns when Julia was developed. Execution times are faster in comparison to other scripting languages like Python\footnote{~\url{www.python.org}} because Julia code is compiled to efficient native code with the help of the Low Level Virtual Machine. In addition, Julia is dynamically typed. This means that the programmer can define types, accelerating the execution time even more. The syntax of the language is easy to understand, making it possible for beginners to get started quickly. With over a thousand contributors, Julia has a large open-source community from which one can expect even more improvements in future times. Lastly, Julia provides a lot of interfaces to open-source and commercial optimization solvers like Gurobi\footnote{~\url{www.gurobi.com}}. These features supported the decision to implement the optimization models in Julia. \\

The section starts with a general overview of the code structure including information about subdirectories and the used open-source packages. Afterwards, the optimization model of the centralized approach is explained. Finally, the implementations for the decentralized optimization model are described.

\subsubsection{General Information}

Rather than defining everything in one Julia script, the approach was followed to divide the source code into separate units. This is a best practice in modern software development that allows to better understand the code and contributes to a more maintainable project. However, Julia is more a scripting language than an object-oriented language. Thus, one had to make some adjustments to provide a structured source code.\\ 

All Julia files are placed into the directory \path{src} that contains several subdirectories. Each of them has a different purpose. There is the \path{src/cases} directory that contains the Julia scripts for setting up a case study system. This directory can contain different case studies, making it possible to easily switch between different scenarios. Inside of \path{src/helpers} several helper scripts are defined that are used while running the decentralized optimization model. This includes methods to print results, calculating the $PTDF$ or several plotting functions to visualize the optimization results. All Julia scripts related to the decentralized optimization model are located in \path{src/optimization}. This compromises for example the modeling of the subproblems or functions to check the convergence of the problem. Lastly, all defined structures that are utilized in the source code are placed in \path{src/structures}. The structures scripts are also separated in corresponding categories, e.g. network elements like generators or penalty terms. There is one main script for running the centralized optimization model \path{src/opf_central_reference.jl} and one for the decentral optimization model using the \gls{admm} named \path{src/opf_admm_decentral.jl}. Both scripts include a case study from the before mentioned directory and the Julia script \path{src/imports.jl} that manages all imports from the subdirectories and the needed Julia packages.\\

All open-source packages that are used within the project are listed in the file \path{Project.toml}. This file is also used to create a reproducable environment for every user. To activate the environment, open the Julia package manager in the root directory of the project and run the command \lstinline[language=sh]{activate ADMM}. All necessary packages are then installed.\\

Gurobi is utilized as a solver as it is the fastest solver for optimization problems world-wide and provides with the Julia package Gurobi\footnote{~\url{www.juliapackages.com/p/gurobi}} an easy-to-use interface. The solver is used in combination with the Julia package JuMP that presents a modelling language for mathematical optimization problems and is introduced by \citet{dunning2017}. The package equips the user with several helper methods to formulate and solve optimization models. Another advantage of JuMP is that one can easily switch between solvers. Thus, it is possible to replace Gurobi with an open-source solver like Clp\footnote{~\url{www.github.com/coin-or/Clp}}. Lastly, the  Julia package PlotlyJS is used to create interactive plots.

\subsubsection{Centralized Problem}

This section illustrates the implementation of the centralized optimization model that is used as a reference model and presents the current state of the energy dispatch framework that is utilized in energy systems world-wide. The corresponding code is shown in the listing below. The linenumbers on the left hand-side are referenced in the following explanation.

\lstinputlisting[language=julia, caption=Implementation of the centralized optimization model, label=jl:com]{../src/opf_central_reference.jl}

First, the necessary packages and Julia scripts are imported in line \texttt{1}. Then the case study is included, providing all elements of the network with the relevant parameters. The code block between line \texttt{5} and \texttt{54} creates the optimization model. In the beginning of the block, helper indexes for all network elements are created. These are used in the later model equations. Afterwards, the $PTDF$ of the network is calculated using the helper function \lstinline[language=julia]{calculate_ptdf()} that is defined in \path{src/helpers/ptdf.jl} and is listed in \ref{sec:appendix:jl:ptdf} for further reference.  As a next step, the JuMP model object \lstinline[language=julia]{m} is initiated and the solver is set to Gurobi in line \texttt{16}. The variable \lstinline[language=julia]{gurobi_env} is defined in the import script \path{src/imports.jl} and suppresses multiple Gurobi license printings. Afterwards, the opimization variables are attached to the JuMP model. The created indexes are used to access the network elements that are stored in an array. The first dimension of all variables represents always the network element as shown in the matrix formulation of section (\ref{sec:app:matrix}). The second dimension represents the time index. The naming convention of the optimization variables reflect the variable names in the optimization equations from section (\ref{sec:app:math-form}). While declaring the variables, the corresponding bounds are set too. Hereby, one can make use of the implemented structures to access the corresponding paramters, e.g. setting the upper bound of the generator power output with the help of attribute \lstinline[language=julia]{max_generation}. This allows to reduce the number of constraints, making the optimization model more simple. In lines \texttt{34} to \texttt{38} an expression is added to the model that calculates the injection at every timestep and node according to the formulation from section (\ref{sec:app:math-form}). The generation from either a generator or storage is included in the injection formulation of a specific timestep and node, if the node is equal to the node of the generating unit. This was implemented by using the ternary operator \lstinline[language=julia]{?:} and the attribute \lstinline[language=julia]{node} of the network element. The ternary operator serves as a short if-else-condition. Next, the objective function of the problem is defined in line \texttt{41} to \texttt{44}. This function sums up the product of the generation decision variables and marginal costs for all network elements and timesteps. For storage network elements both discharging power and charging power are considered in the costs. The last part of the model setup introduces all constraints. Line \texttt{17} attaches the energy balance constraint to the model. This constraint uses the before defined expression for the injection term and makes sure that the sum of all node injections at a specific timestep equals zero. Afterwards, the upper and lower line constraint limit is implemented. As explained in the previous section, this constraint was transformed into two equality constraints by introducing two slack variables respectively. Due to a Julia type error, the dot product between the $PTDF$ of one line and the inejection term for one timestep had to be calculated by summing up the single values of the dot product. Lastly, the energy level constraint of the storages is added to the model. This constraint makes sure that the current energy level consists of the energy level of the previous timestep and the charging power minus the power that is withdrawn. The ternary operator is utilized again to set the initial energy level to zero. In line \texttt{57}, the command is run to solve the optimization model \lstinline[language=julia]{m}. The rest of the implementation covers the output of the optimization variables and additional information like the system price or the line utilization.


\subsubsection{Decentralized Problem}
