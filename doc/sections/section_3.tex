\chead{\textit{Application}}  				
\section{Application}

%TODO Write introduction to chapter

\subsection{Modeling Framework}
\label{sec:app:mod-framework}

This section introduces the reader to all relevant information about the modelling framework that is used to model a real-life application. The modelling framework has to cover certain requirements. Firstly, there should be generators that produce electrical power. The power output is only limited by the maximum capacity of the generator. There exist no ramping constraints or minimum up- and down-times. Each generator has marginal costs and is connected to a specific node. To depict these requirements in Julia, a generator structure was implemented as you can see in the following code snippet. In addition to the stated requirements, the structure also contains a colour and a name. These attributes are mainly used for evaluation reasons and are not important for modelling purposes. 

\lstinputlisting[language=julia, firstline=7, lastline=13, caption=Julia structure for a node element]{../src/structures/network_elements.jl}

Another part of the modelling framework is a storage unit. Storages should be able to store a surplus of energy as well as deliver electrical power by discharging their capacity. The power input and output is also limited. In addition, a storage unit should only be able to store a certain amount of energy. This is depicted by the storage level. As generators, storages have specific marginal costs for charging and discharging and are connected to a specific node. A Julia structure was implemented respectively.\\

As written before, generators and storages are located at network nodes. These nodes have a specific demand that should be matched by the output of the generating units. For modelling purposes, it is also crucial to define a slack node to compensate the power flow balance. The node structure was implemented as follows:

\lstinputlisting[language=julia, firstline=1, lastline=5, caption=Julia structure for a generator element]{../src/structures/network_elements.jl}

The last element of the framework is a transmission line. This element connects nodes and enables the exchange of energy. Transmission lines are characterized by their maximum capacity and their susceptance value. A Julia structure was also implemented for this network element.\\

Lastly, the modelling framework has to consider multi-periods. This is crucial since without multi periods, it would not make sense to include storages into the system.\\

All structures are defined in \path{src\structures\network_elements.jl} and can be found in \ref{app:jl:ne}.


\subsection{Mathematical Formulations}
\label{sec:math-form}

As written in the introduction, the aim of this thesis is to develop a framework to minimize the total system costs of a electrical network in a decentralized manner. This means that the costs are optimized without a central entity. Thus, the generating units are able to derive their own optimal decisions without releasing sensible information like their marginal costs. This section presents the mathematical formulations of the optimization problem. Since the solution of the decentralized problem will be compared with the solution of the centralized problem and the decentralized problem is based on the centralized problem, the centralized optimization model is introduced first.

\subsubsection{Centralized Optimization Problem}

The total system costs of a electrical network are the sum of generation costs of all participating units over all time steps. With regard to the modeling framework, this means that the system costs are composed of the generator costs and the storage costs. The centralized optimization problem can be formulated as follows:

\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}}\sum_{g\in\mathcal{G}}c_g*P_g(t) + \sum_{s\in\mathcal{S}}c_s*(P_s^d(t)+P_s^c(t))\\
		 \text{s.t. } \quad & 0 \leq P_g(t) \leq \overline{P_g} && \forall g \in \set{G}, t \in \set{T} \label{eq:com:con:max-g}\\
		 & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:max-sd}\\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:max-sc}\\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:s-level-max}\\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall s \in \set{S}, t \in \set{T} \label{eq:com:con:s-level}\\
		 & I_n(t) = \sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t) = 0 && \forall t \in \set{T}, n \in \set{N} \label{eq:com:con:eb}\\
		 & -\overline{L_l} \leq PTDF * I_n(t) \leq \overline{L_l} && \forall l \in \set{L}, t \in \set{T}, n \in \set{N} \label{eq:com:con:pf}
	\end{align}
\end{subequations}

Hereby, $\mathcal{G}$ represents the set of generators and $\mathcal{S}$ the set of storage respectively. $\mathcal{T}$ includes all considered timesteps. The optimization problem is constrained to meet the requirements written in section (\ref{sec:app:mod-framework}). First of all, equation (\ref{eq:com:con:max-g}) limits the maximum output of all generators where $\overline{P_g}$ is the maximum power generation of the considered generator. Equations (\ref{eq:com:con:max-sd}) and (\ref{eq:com:con:max-sc}) set the boundaries of all storages and equation (\ref{eq:com:con:s-level-max}) ensures that the storage level of all storages remains between zero and the maximum storage level $\overline{E_s}$. The storage level at a specific time step can be calculated as follows:

\begin{equation}
	\label{eq:storage-level}
	E_s(t) = E_s(t-1) + P_s^c(t) - P_s^d(t)
\end{equation}

To get a consistent form of all constraints, equation (\ref{eq:storage-level}) is rearranged to equal zero and integrated in the optimization problem as equation (\ref{eq:com:con:s-level}). Hereby, $P_s^c(t)$ denotes the charging output of a storage $s$ at a timestep $t$ and $P_s^d(t)$ the discharging output. Equation (\ref{eq:com:con:eb}) is the so called energy balance. This constraint ensures that the demand at every node and every time step is met. The energy balance is also referred to as the injection at node $n$ at time step $t$. The injection term is used in the last constraint (\ref{eq:com:con:pf}) that establishs the network constraints. Here, the power flows on each transmission line are limited by the maximum line capacity $\overline{L_l}$. The line utilization for each transmission line is calculated by multiplying the \gls{ptdf} with the injection term $I_n(t)$.\\

	%TODO Explain PTDF, see maybe document from EMOD.
	
To solve the optimization problem, all relevant information has to be shared with the central entity. In the example above this includes marginal costs and the maximal capacities of the generating units. The central entity is then able to derive the optimal dispatch plan that minimizes the total system costs and informs the generating units about their generation schedule. Thus, the generating units are not able to optimize their decision on their own because the central entity is needed for coordination.	

\subsubsection{Decentralized Optimization Problem}
\label{sec:dom}

% TODO Add reference for ADMM explanation
The generating units in the centralized optimization problem are not able to optimize on their own because a central entity is needed to coordinate the system constraints (\ref{eq:com:con:eb}) and (\ref{eq:com:con:pf}). These constraints prevent that the solution is obtained by optimizing per generating unit because both include all decision variables of the optimization problem. This is the reason why these constraints are called complicating constraints. If resolved, it would be possible to derive the optimal dispatch plan per generating unit and without sharing sensible information like marginal costs. As written in \ref{admm}, the \gls{admm} provides a technique to resolve these constraints, making the problem decomposable and thus enables the path to a decentralized mechanism. \gls{admm} is only working for equality constraints. Thus, the power flow inequality constraint (\ref{eq:com:con:pf}) is transformed into two equality constraints by introducing two slack variables $R^{ref}_l$ and $R^{cref}_l$ for each tranmission line $l$. The optimization problem evolves to the following:

\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}}\sum_{g\in\mathcal{G}}c_g*P_g(t) + \sum_{s\in\mathcal{S}}c_s*(P_s^d(t)+P_s^c(t)) \label{eq:dom:relaxed-constraints}\\
		 \text{s.t.} \quad & 0 \leq P_g(t) \leq \overline{P_g} && \forall g \in \set{G}, t \in \set{T} \\
		 & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall s \in \set{S}, t \in \set{T} \\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall s \in \set{S}, t \in \set{T} \\
		 & I_n(t) = \sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t) = 0 && \forall t \in \set{T}, n \in \set{N} \label{eq:dom:injection-term} \\
		 & PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l} = 0 && \forall l \in \set{L}, t \in \set{T}, n \in \set{N} \label{eq:dom:con:pf-upper} \\
		 & R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l} = 0 && \forall l \in \set{L}, t \in \set{T}, n \in \set{N} \label{eq:dom:con:pf-lower}
	\end{align}
\end{subequations}

The slack variable $R_l^{ref}$ ensures that the upper bound of the transmission line capactiy is kept, while slack variable $R_l^{cref}$ ensures the lower limit. Both variables are added as additional decision variables. Instead of two complicating constraints, one has to handle three complicating constraints. If these constraints are relaxed, the main problem decomposes into a generator and a storage subproblem.\\

Relaxing the complicating variables is done by implementing a max-min problem using the dual variables of the complicated constraints. Hereby, $\lambda$ is the dual of the energy balance constraint, $\mu$ and $\rho$ are the duals of the upper and lower power flow constraint respectively. Since the objective function is a linear cost function, \gls{lr} is not applicable. Thus, the complicated constraints are relaxed by applying \gls{alr}. A penalty term for each dual variable is introduced. The penalty terms equal zero in the optimality point and contribute to a faster convergence. The optimization problem of (\ref{eq:dom:relaxed-constraints}) derives to:

\begin{subequations}
	\begin{align}
		\max{(\lambda, \mu, \rho)} \label{eq:dom:fixed-duals} \\
		 & \min \quad \sum_{t\in\mathcal{T}}\sum_{g\in\mathcal{G}}c_g*P_g(t) + \sum_{s\in\mathcal{S}}c_s*(P_s^d(t)+P_s^c(t)) \nonumber \\
		 & + \lambda * \left[\sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t)\right]\nonumber \\
		 & + \frac{\gamma}{2} * \left[\sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t)\right]^2 \nonumber \\
		 & + \mu * \left[PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l}\right] \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l}\right]^2 \nonumber \\
		 & + \rho * \left[R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l}\right]\nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l}\right]^2 \nonumber
	\end{align}
	\begin{align}
		 \text{s.t. } \quad & 0 \leq P_g(t) \leq \overline{P_g} && \forall g \in \set{G}, t \in \set{T}\\\
		 & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall s \in \set{S}, t \in \set{T}
	\end{align}
\end{subequations}

Variable $\gamma$ is a positive constant and is the only parameter needed for the \gls{admm}. Due to the quadratic terms of the relaxed complicating constraitns, the first derivatives of the objective function is not fixed anymore but continuous. This is also a necessary condition for the convergence of the algorithm. Still, the optimization problem in equation (\ref{eq:dom:fixed-duals}) is not decomposable because of the introduced dual variables. The problem is further relaxed by fixing the dual variable to given values $\overline{\lambda}$, $\overline{\mu}$, $\overline{\rho}$. The problem formulation becomes:

\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}}\sum_{g\in\mathcal{G}}c_g*P_g(t) + \sum_{s\in\mathcal{S}}c_s*(P_s^d(t)+P_s^c(t)) \label{eq:dom:final} \\
		 & + \overline{\lambda} * \left[\sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t)\right]\nonumber \\
		 & + \frac{\gamma}{2} * \left[\sum_{g\in\mathcal{G}}P_g(t) + \sum_{s\in\mathcal{S}}(P_s^d(t)-P_s^c(t))-D_n(t)\right]^2 \nonumber \\
		 & + \overline{\mu} * \left[PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l}\right] \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(t) + R^{ref}_l(t) - \overline{L_l}\right]^2 \nonumber \\
		 & + \overline{\rho} * \left[R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l}\right]\nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(t) - PTDF * I_n(t) - \overline{L_l}\right]^2\nonumber \\
		 \text{s.t.} \quad & 0 \leq P_g(t) \leq \overline{P_g} && \forall g \in \set{G}, t \in \set{T}\\\
		 & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall s \in \set{S}, t \in \set{T}\\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall s \in \set{S}, t \in \set{T}
	\end{align}
\end{subequations}

% TODO Add reference for ADMM explanation
Because of the product of the decision variable $P_{\mathcal{G}}$, $P_{\mathcal{S}}^d$ and $P_{\mathcal{S}}^c$ in all penalty terms, the optimization model is still not decomposable. At this step, the \gls{admm} comes into action and provides a possibility to solve the problem in a decomposable way. As written in \ref{admm}, \gls{admm} fixes each decision variable to the previous iteration value. Thus, one is finally able to derive the generator and storage subproblem. Out of simplicity, the overline symbol on the dual variables is omitted in the next equations.


\subsubsection*{Generator Subproblem}

In the following, the optimization model for a specific generator $g$ is derived. The problem is only optimized by the decision variable $P_{g}$ of this generator and the corresponding slack variables of the power flow constraint. With the help of \gls{admm}, decision variables $P_{\mathcal{S}}^d$ and $P_{\mathcal{S}}^c$ are fixed to the values of the previous iteration. The power output of all other generators $P_{g \notin \mathcal{G}}$ is fixed too. Any constraint related to these variables can be removed. Another parameter $v$ is added to the problem formulation that indicates the iteration number. Obviously, for decision variable $P_{g}$ one takes the current iteration number $v$ while for the storages and other generators one takes the previous iteration $v-1$. The first derivative of the objective function shows that the objective function can be further simplified by removing terms related to $P_{g \notin \mathcal{G}}$, $P_{\mathcal{S}}^d$ and $P_{\mathcal{S}}^c$. The penalty terms can not be further simplified because of the quadratic term. The optimization model for a single generator yields:

% When writing multi-line equations with the align, align* or aligned environments, the \left and \right commands must be balanced on each line and on the same side of &. The solution is to use "invisible" brackets to balance things out, i.e. adding a \right. at the end of the first line, and a \left. at the start of the second line after &:
\begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}} c_g*P_g(v, t) + \lambda * P_g(v, t) \label{eq:sub:gen}\\
		 & + \frac{\gamma}{2} * \left[ P_g(v, t) + \sum_{g\notin\mathcal{G}}P_g(v-1,t) \right. \nonumber \\
		 & \qquad \left. + \sum_{s\in\mathcal{S}}(P_s^d(v-1, t)-P_s^c(v-1, t))-D_n(t)\right]^2 \label{eq:sub:gen:eb} \\
		 & + \mu * PTDF * P_g(v, t) \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(v, t) + R^{ref}_l(v, t) - \overline{L_l}\right]^2 \nonumber \\
		 & - \rho * PTDF * P_g(v, t) \nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - PTDF * I_n(v, t) - \overline{L_l}\right]^2\nonumber \\
		 \text{s.t.} \quad & 0 \leq P_g(v, t) \leq \overline{P_g} && \forall t \in \set{T}
	\end{align}
\end{subequations}

 The term inside of the brackets of equation (\ref{eq:sub:gen:eb}) is once again the injection formulation. In comparison to equation (\ref{eq:dom:injection-term}), the power output of the other generators and storages is not a variable anymore but a parameter. Hence, the power output of the specific generator $P_{g}$ is excluded from the sum.\\
 
 As for now, the specific generator needs to know the previous dispatch of all other units to compute the injection. This is in contradiction to the aim of this thesis to create a decentralized framework in which sensitive information is not shared with other participants. That includes the power dispatch of the previous iteration. To overcome the problem, the coordinating algorithm provides the summed power outputs of the other generators and storages. Using the sum prevents the fact that the specific generators needs to know the acutal power values. Since the power output of the specific generator is also included, one has to subtract the power output from the last iteration of the specific generator from the sum. \\
 
 The optimization model in (\ref{eq:sub:gen}) is further rearranged by summarising the dual variables. In addition, penalty terms for the decision variables are introduced. These penalty terms calculate the difference between the current iteration value and the last iteration value. Since the slack variables of the power flow constraint have to be the same for all subproblems, the penalty term of these decision variables is compared against the average value of the last iteration of all subproblems. In the optimality point, these penalty terms become zero. Subsequently, they also contribute to a faster convergence. Finally, the generator subproblem becomes:
 
 \begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}} c_g*P_g(v, t) \label{eq:sub:gen-final}\\
		 & + P_g(v, t) * (\lambda + (\mu - \rho) * PTDF) \nonumber \\ 
		 & + \frac{\gamma}{2} * \left[P_g(v, t) + \sum P_{\mathcal{G}}(v-1,t) - P_g(v-1, t) \right. \nonumber \\
		 & \qquad \left. + \sum P_{\mathcal{S}}^d(v-1, t) - \sum P_{\mathcal{S}}^c(v-1, t) - D_n(t)\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(v, t) + R^{ref}_l(v, t) - \overline{L_l}\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - PTDF * I_n(v, t) - \overline{L_l}\right]^2\nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{ref}_l(v, t) - \overline{R^{ref}_l}(v-1, t)  \right]^2 \nonumber\\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - \overline{R^{cref}_l}(v-1, t)  \right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[P_g(v, t) - P_g(v-1, t)\right]^2 \nonumber \\
		 \text{s.t.} \quad & 0 \leq P_g(v, t) \leq \overline{P_g} && \forall t \in \set{T}
	\end{align}
\end{subequations}

\subsubsection*{Storage Subproblem}

This section derives the optimization model for a specific storage $s$. The problem only includes decision variables $P_{s}^d$, $P_{s}^c$ of the storage $s$ and the corresponding slack variables of the power flow constraint. As for the generator subproblem, all other decision variables from the main optimization model are fixed to the values of the previous iteration. Thus, constraints related to generators or ther storages can be removed. \\

The derivation of the optimization model for the storage subproblem is nearly the same as for the generator. Therefore a detail decsription of the derivation is omitted and the reader is referred to the generator subproblem for further detail. If the previous iteration values for the generators and other storages as well as the penalty terms are added, the storage subproblem yields:

 \begin{subequations}
	\begin{align}
		 \min \quad & \sum_{t\in\mathcal{T}} c_s*(P_s^d(v, t) + P_s^c(v, t))\label{eq:sub:stor}\\
		 & + (P_s^d(v, t) - P_s^c(v, t)) * (\lambda + (\mu - \rho) * PTDF) \nonumber \\ 
		 & + \frac{\gamma}{2} * \left[\sum P_{\mathcal{G}}(v-1,t) \right. \nonumber \\ 
		 & \qquad \left. + P_s^d(v, t) + \sum P_{\mathcal{S}}^d(v-1, t) - P_s^d(v-1, t) \right. \nonumber \\
		 & \qquad \left. - P_s^c(v, t) - (\sum P_{\mathcal{S}}^c(v-1, t) -  P_s^c(v-1, t)) - D_n(t)\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[PTDF * I_n(v, t) + R^{ref}_l(v, t) - \overline{L_l}\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - PTDF * I_n(v, t) - \overline{L_l}\right]^2\nonumber \\
		 & + \frac{\gamma}{2} * \left[R^{ref}_l(v, t) - \overline{R^{ref}_l}(v-1, t)  \right]^2 \nonumber\\
		 & + \frac{\gamma}{2} * \left[R^{cref}_l(v, t) - \overline{R^{cref}_l}(v-1, t)  \right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[P_s^d(v, t) - P_s^d(v-1, t)\right]^2 \nonumber \\
		 & + \frac{\gamma}{2} * \left[P_s^c(v, t) - P_s^c(v-1, t)\right]^2 \nonumber \\
		 \text{s.t.} \quad & 0 \leq P_s^d(t) \leq \overline{P_s} && \forall t \in \set{T} \\
		 & 0 \leq P_s^c(t) \leq \overline{P_s} && \forall t \in \set{T}\\
		 & 0 \leq E_s(t) \leq \overline{E_s} && \forall t \in \set{T}\\
		 & E_s(t) - E_s(t-1) - P_s^c(t) + P_s^d(t) = 0 && \forall t \in \set{T}
	\end{align}
\end{subequations}

\subsubsection{Matrix Notation}

It is often common to formulate optimization problems in a matrix notation. With this notation it is much easier to understand multidimensional optimization problems. As for this thesis, several dimensions like time, nodes, lines are included. Thus, it would be benificial for the reader to refer to the matrix notation if anything is unclear. In addition, \citet{Boyd-2010-DistributedOptimizationStatistical} also uses matrix notation to explain the \gls{admm}. Typically, \gls{admm} solves optimization problems in the form of:

\begin{subequations}
	\begin{align}
		\min{(x, z)} \quad & f(x) + g(z) \label{eq:admm:gen}\\
		\text{s.t. } \quad & \vb{A}x + \vb{B}z = c \label{eq:admm:gen:con1}
	\end{align}
\end{subequations}

If applied to the formulations of the previous sections, $f(x)$ would be the generator costs and $g(z)$ the storage costs. The problem in (\ref{eq:admm:gen}) would be extended by the corresponding constraints for generators and storages. In addition, the power flow constraint would be added as another system constraint like equation (\ref{eq:admm:gen:con1}). The matrix notation can also be decomposed by applying the steps described in section (\ref{sec:dom}). \\

According to \citet{Boyd-2010-DistributedOptimizationStatistical}, \gls{admm} is often written in a shorter, so called scaled form. In this form, the linear and quadratic terms of the objective function are combined and the dual variables are scaled. This yields a much shorter formulation. As an example, the scaled dual variable of the energy balance is derived. First, one defines a residual term of the energy balance constraint.

\begin{equation}
	\vb{r} = \vb{N_\mathcal{G}}*\vb{P_\mathcal{G}} + \vb{N_\mathcal{S}}*(\vb{P_\mathcal{S}^d} - \vb{P_\mathcal{S}^c}) - \vb{D_\mathcal{N}} = \vb{I_\mathcal{N}}
\end{equation}

Here, $\vb{N_\mathcal{G}}$ and $\vb{N_\mathcal{S}}$ are the identity matrices indicating the node location of every generator and storage. Inserting the residual term $r$ into the corresponding part of the optimization problem yields:

\begin{equation}
	\vb{\lambda} * \vb{r} + \frac{\gamma}{2} * || \vb{r} ||^2_2 = \frac{\gamma}{2} || \vb{r} + \frac{1}{\gamma}\vb{\lambda} ||^2_2 - \frac{1}{2\gamma}|| \vb{\lambda} ||^2_2 = \frac{\gamma}{2} || \vb{r} + \vb{\hat{\lambda}} ||^2_2 - \frac{\gamma}{2}|| \vb{\hat{\lambda}} ||^2_2 \label{eq:derivation_lambda_hat}
\end{equation}

The transformation is not very straight forward but allows to further simplify the  optimization problem. With $\vb{\hat{\lambda}} = \frac{1}{\gamma}*\vb{\lambda}$, one gets the scaled dual variable of $\vb{\lambda}$. Using the scaled dual variable makes the problem formulation much shorter because the last term $- \frac{\gamma}{2}|| \vb{\hat{\lambda}} ||^2_2$ of equation (\ref{eq:derivation_lambda_hat}) does not contain any optimization variable. Hence, this term can be removed. The other dual variables can be replaced respectively. In the following the generator subproblem and the storage subproblem are formulated using the scaled form of the \gls{admm}.

\subsubsection*{Generator Subproblem}

The generator costs in matrix notation are formulated as follows:

\begin{subequations}
	\begin{align}
		f(x) &= f(\vb{P_\mathcal{G}}) = \vb{P_\mathcal{G}}^T * \vb{c_\mathcal{G}}\\
		& = \begin{bmatrix}
			P_{g_1}(t_1) & \dots & P_{g_n}(t_1) \\
			\vdots & \ddots & \vdots \\
			P_{g_1}(t_n) & \dots & P_{g_n}(t_n)
		\end{bmatrix} * \begin{bmatrix}
			c_{g_1} \\
			\vdots \\
			c_{g_n}
		\end{bmatrix}
	\end{align}
\end{subequations}

If this formulation is applied to the generator optimization problem of equation (\ref{eq:sub:gen-final}), the matrix notation yields:

 \begin{subequations}
	\begin{align}
		 \min \quad & \vb{P_g}^T * \vb{c}_g \\
		 & + \frac{\gamma}{2} * \big\| \vb{P_g} + \sum \vb{P_\mathcal{G}}(v-1) - \vb{P_g}(v-1) \nonumber \\
		 & \qquad + \sum \vb{P_\mathcal{S}^d}(v-1) - \sum \vb{P_\mathcal{S}^c}(v-1) - \vb{D_n} + \frac{\vb{\lambda}}{\gamma} \big\|^2_2 \label{eq:dom-matrix:eb} \\
		 & + \frac{\gamma}{2} * \big\| PTDF * \vb{I_n} + \vb{R^{ref}} - \vb{\overline{L}} + \frac{\vb{\mu}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{cref}} - PTDF * \vb{I_n} - \vb{\overline{L}} + \frac{\vb{\rho}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{ref}} - \vb{\overline{R^{ref}}}(v-1)  \big\|^2_2 \nonumber\\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{cref}} - \vb{\overline{R^{cref}}}(v-1) \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{P_g} - \vb{P_g}(v-1) \big\|^2_2 \nonumber \\
		 \text{s.t.} \quad & \vb{0} \leq \vb{P_g} \leq \vb{\overline{P_g}}
	\end{align}
\end{subequations}

Hereby, the matrices of the previous iteration values in equation (\ref{eq:dom-matrix:eb}) are summed up for all generators and storages, making these values only time-dependent. One should also note the norm formulation in the quadratic terms of the formulation. This norm is further examined in the result section of this thesis.

\subsubsection*{Storage Subproblem}

The storage costs in matrix notation are formulated as follows:

\begin{subequations}
	\begin{align}
		g(z) &= g(\vb{P_\mathcal{S}^d}, \vb{P_\mathcal{S}^c})\\
		& = \left(\vb{P_\mathcal{S}^d} + \vb{P_\mathcal{S}^c}\right)^T * \vb{c_\mathcal{S}} \\
		& = \left(\begin{bmatrix}
			P_{s_1}^d(t_1) & \dots & P_{s_n}^d(t_1) \\
			\vdots & \ddots & \vdots \\
			P_{s_1}^d(t_n) & \dots & P_{s_n}^d(t_n)
		\end{bmatrix} + \begin{bmatrix}
			P_{s_1}^c(t_1) & \dots & P_{s_n}^c(t_1) \\
			\vdots & \ddots & \vdots \\
			P_{s_1}^c(t_n) & \dots & P_{s_n}^c(t_n)
		\end{bmatrix} \right) * \begin{bmatrix}
			c_{s_1} \\
			\vdots \\
			c_{s_n}
		\end{bmatrix}
	\end{align}
\end{subequations}

If this formulation is applied to the storage optimization problem of equation (\ref{eq:sub:stor}), the matrix notation yields:

 \begin{subequations}
	\begin{align}
		 \min \quad & \left(\vb{P_s^d} + \vb{P_s^c}\right)^T * \vb{c_s}\\
		 & + \frac{\gamma}{2} * \big\| \sum \vb{P_\mathcal{G}}(v-1) \nonumber \\ 
		 & \qquad + \vb{P_s^d} + \sum \vb{P_\mathcal{S}^d}(v-1) - \vb{P_s^d}(v-1) \nonumber \\
		 & \qquad - \vb{P_s^c} - (\sum \vb{P_\mathcal{S}^c}(v-1) -  \vb{P_s^c}(v-1)) - \vb{D_n} + \frac{\vb{\lambda}}{\gamma} \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| PTDF * \vb{I_n} + \vb{R^{ref}} - \vb{\overline{L}} + \frac{\vb{\mu}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{cref}} - PTDF * \vb{I_n} - \vb{\overline{L}} + \frac{\vb{\rho}}{\gamma}\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{ref}} - \vb{\overline{R^{ref}}}(v-1)  \big\|^2_2 \nonumber\\
		 & + \frac{\gamma}{2} * \big\| \vb{R^{cref}} - \vb{\overline{R^{cref}}}(v-1) \big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{P_s^d} - \vb{P_s^d}(v-1)\big\|^2_2 \nonumber \\
		 & + \frac{\gamma}{2} * \big\| \vb{P_s^c} - \vb{P_s^d}(v-1)\big\|^2_2 \nonumber \\
		 \text{s.t.} \quad & \vb{0} \leq \vb{P_s^d} \leq \vb{\overline{P_s}} \\
		 & \vb{0} \leq \vb{P_s^c} \leq \vb{\overline{P_s}} \\
		 & \vb{0} \leq \vb{E_s} \leq \vb{\overline{E_s}}\\
		 & \vb{0} = \vb{E_s} - \vb{E_s^{t-1}} - \vb{P_s^c} + \vb{P_s^d}
	\end{align}
\end{subequations}


\subsection{Implementation of in Julia}

\subsubsection{Centralized problem}

\subsubsection{Decentralized problem}
